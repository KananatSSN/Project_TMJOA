{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbea1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "def remove_background_slices(img_data, threshold=0, clip_min=-250):\n",
    "    \"\"\"\n",
    "    Remove slices from all three dimensions where all voxels are <= threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    - img_data: 3D numpy array\n",
    "    - threshold: background threshold value\n",
    "    - clip_min: minimum value to clip voxels to (default: -250)\n",
    "    \n",
    "    Returns:\n",
    "    - Cropped 3D numpy array\n",
    "    \"\"\"\n",
    "    # Clip values below clip_min to clip_min\n",
    "    img_data = np.clip(img_data, clip_min, None)\n",
    "    \n",
    "    # Find non-background slices for each dimension\n",
    "    non_bg_slices = []\n",
    "    \n",
    "    for axis in range(3):\n",
    "        # Check each slice along this axis\n",
    "        max_vals = np.max(img_data, axis=tuple(i for i in range(3) if i != axis))\n",
    "        non_bg_indices = np.where(max_vals > threshold)[0]\n",
    "        \n",
    "        if len(non_bg_indices) > 0:\n",
    "            non_bg_slices.append((non_bg_indices[0], non_bg_indices[-1] + 1))\n",
    "        else:\n",
    "            # If all slices are background, keep at least one\n",
    "            non_bg_slices.append((0, 1))\n",
    "    \n",
    "    # Crop the image\n",
    "    cropped = img_data[\n",
    "        non_bg_slices[0][0]:non_bg_slices[0][1],\n",
    "        non_bg_slices[1][0]:non_bg_slices[1][1],\n",
    "        non_bg_slices[2][0]:non_bg_slices[2][1]\n",
    "    ]\n",
    "    \n",
    "    return cropped\n",
    "\n",
    "def pad_or_crop_to_cube(img_data, target_size, pad_value=0):\n",
    "    \"\"\"\n",
    "    Pad or crop image to cubic dimensions (target_size, target_size, target_size).\n",
    "    When cropping: takes from start (0:target_size)\n",
    "    When padding: centers the image (pads on both sides)\n",
    "    \n",
    "    Parameters:\n",
    "    - img_data: 3D numpy array\n",
    "    - target_size: desired cubic dimension\n",
    "    - pad_value: value to use for padding (default: 0)\n",
    "    \n",
    "    Returns:\n",
    "    - Cubic 3D numpy array\n",
    "    \"\"\"\n",
    "    current_shape = img_data.shape\n",
    "    result = np.full((target_size, target_size, target_size), pad_value, dtype=img_data.dtype)\n",
    "    \n",
    "    # Calculate start and end indices for each dimension\n",
    "    for axis in range(3):\n",
    "        current_dim = current_shape[axis]\n",
    "        \n",
    "        if current_dim >= target_size:\n",
    "            # Crop: take from start (0:target_size)\n",
    "            start_src = 0\n",
    "            end_src = target_size\n",
    "            start_dst = 0\n",
    "            end_dst = target_size\n",
    "        else:\n",
    "            # Pad: place in center (pad on both sides)\n",
    "            start_src = 0\n",
    "            end_src = current_dim\n",
    "            start_dst = (target_size - current_dim) // 2\n",
    "            end_dst = start_dst + current_dim\n",
    "        \n",
    "        if axis == 0:\n",
    "            x_src, x_dst = (start_src, end_src), (start_dst, end_dst)\n",
    "        elif axis == 1:\n",
    "            y_src, y_dst = (start_src, end_src), (start_dst, end_dst)\n",
    "        else:\n",
    "            z_src, z_dst = (start_src, end_src), (start_dst, end_dst)\n",
    "    \n",
    "    # Copy data\n",
    "    result[x_dst[0]:x_dst[1], y_dst[0]:y_dst[1], z_dst[0]:z_dst[1]] = \\\n",
    "        img_data[x_src[0]:x_src[1], y_src[0]:y_src[1], z_src[0]:z_src[1]]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def resize_image(img_data, target_size):\n",
    "    \"\"\"\n",
    "    Resize image to (target_size, target_size, target_size) using interpolation.\n",
    "    \n",
    "    Parameters:\n",
    "    - img_data: 3D numpy array\n",
    "    - target_size: desired output dimension\n",
    "    \n",
    "    Returns:\n",
    "    - Resized 3D numpy array\n",
    "    \"\"\"\n",
    "    current_shape = img_data.shape\n",
    "    zoom_factors = [target_size / current_shape[i] for i in range(3)]\n",
    "    \n",
    "    # Use order=1 for linear interpolation (good for medical images)\n",
    "    # Use order=0 for nearest neighbor (preserves label values for segmentation masks)\n",
    "    resized = zoom(img_data, zoom_factors, order=1)\n",
    "    \n",
    "    return resized\n",
    "\n",
    "def process_nifti(input_path, output_path, threshold=0, n=128, m=64, pad_value=0, clip_min=-250):\n",
    "    \"\"\"\n",
    "    Complete pipeline to process NIfTI image.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_path: path to input .nii or .nii.gz file\n",
    "    - output_path: path to save processed .nii.gz file\n",
    "    - threshold: background threshold for slice removal\n",
    "    - n: cubic dimension after cropping/padding\n",
    "    - m: final dimension after resizing\n",
    "    - pad_value: value to use for padding (default: 0)\n",
    "    - clip_min: minimum value to clip voxels to (default: -250)\n",
    "    \"\"\"\n",
    "    # Load the NIfTI image\n",
    "    # print(f\"Loading {input_path}...\")\n",
    "    nii_img = nib.load(input_path)\n",
    "    img_data = nii_img.get_fdata()\n",
    "    \n",
    "    # print(f\"Original shape: {img_data.shape}\")\n",
    "    \n",
    "    # Step 1: Remove background slices\n",
    "    # print(f\"Removing background slices (threshold={threshold})...\")\n",
    "    cropped = remove_background_slices(img_data, threshold, clip_min)\n",
    "    # print(f\"After cropping: {cropped.shape}\")\n",
    "    \n",
    "    # Step 2: Pad/crop to cubic dimensions\n",
    "    # print(f\"Padding/cropping to ({n}, {n}, {n})...\")\n",
    "    cubic = pad_or_crop_to_cube(cropped, n, pad_value)\n",
    "    # print(f\"After cubic transform: {cubic.shape}\")\n",
    "    \n",
    "    # Step 3: Resize to final dimensions\n",
    "    # print(f\"Resizing to ({m}, {m}, {m})...\")\n",
    "    resized = resize_image(cubic, m)\n",
    "    # print(f\"Final shape: {resized.shape}\")\n",
    "    \n",
    "    # Create new NIfTI image with updated affine matrix\n",
    "    # Scale the affine to account for the resize\n",
    "    new_affine = nii_img.affine.copy()\n",
    "    scale_factor = img_data.shape[0] / m  # Approximate scaling\n",
    "    new_affine[:3, :3] = new_affine[:3, :3] * scale_factor\n",
    "    \n",
    "    # Save the processed image\n",
    "    # print(f\"Saving to {output_path}...\")\n",
    "    new_nii = nib.Nifti1Image(resized, new_affine)\n",
    "    nib.save(new_nii, output_path)\n",
    "    # print(\"Done!\")\n",
    "    \n",
    "    return resized\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Customize these parameters\n",
    "#     input_file = r\"d:\\Kananat\\Data\\2_Masked\\47-4881 L 2014_masked.nii.gz\"\n",
    "#     output_file = \"output_image.nii.gz\"\n",
    "#     threshold = -250  # Background threshold\n",
    "#     n = 128  # Cubic dimension\n",
    "#     m = 128   # Final dimension\n",
    "#     pad_value = -250  # Value to use for padding\n",
    "#     clip_min = -250  # Minimum voxel value (values below this will be set to this)\n",
    "    \n",
    "#     processed_img = process_nifti(\n",
    "#         input_path=input_file,\n",
    "#         output_path=output_file,\n",
    "#         threshold=threshold,\n",
    "#         n=n,\n",
    "#         m=m,\n",
    "#         pad_value=pad_value,\n",
    "#         clip_min=clip_min\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "219fd1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1: 5011620_2025_02_13_L_masked.nii.gz\n",
      "Processing file 2: 5011620_2025_02_13_R_masked.nii.gz\n",
      "Processing file 3: 5218852_2016_05_26_L_masked.nii.gz\n",
      "Processing file 4: 5218852_2016_05_26_R_masked.nii.gz\n",
      "Processing file 5: 5237193_2016_04_05_L_masked.nii.gz\n",
      "Processing file 6: 5237193_2016_04_05_R_masked.nii.gz\n",
      "Processing file 7: 5425927_2016_04_24_L_masked.nii.gz\n",
      "Processing file 8: 5425927_2016_04_24_R_masked.nii.gz\n",
      "Processing file 9: 5450_2016_02_26_L_masked.nii.gz\n",
      "Processing file 10: 5450_2016_02_26_R_masked.nii.gz\n",
      "Processing file 11: 5630067_2024_01_31_R_masked.nii.gz\n",
      "Processing file 12: 5724983_2016_07_02_L_masked.nii.gz\n",
      "Processing file 13: 5724983_2016_07_02_R_masked.nii.gz\n",
      "Processing file 14: 5734770_2016_01_17_L_masked.nii.gz\n",
      "Processing file 15: 5734770_2016_01_17_R_masked.nii.gz\n",
      "Processing file 16: 5841636_2016_01_29_L_masked.nii.gz\n",
      "Processing file 17: 5841636_2016_01_29_R_masked.nii.gz\n",
      "Processing file 18: 592326_2016_02_20_L_masked.nii.gz\n",
      "Processing file 19: 592326_2016_02_20_R_masked.nii.gz\n",
      "Processing file 20: 596269_2016_03_26_L_masked.nii.gz\n",
      "Processing file 21: 596269_2016_03_26_R_masked.nii.gz\n",
      "Processing file 22: 6034373_2024_10_08_L_masked.nii.gz\n",
      "Processing file 23: 6034373_2024_10_08_R_masked.nii.gz\n",
      "Processing file 24: 630010001_2024_05_27_L_masked.nii.gz\n",
      "Processing file 25: 630010001_2024_05_27_R_masked.nii.gz\n",
      "Processing file 26: 639054_2024_03_08_L_masked.nii.gz\n",
      "Processing file 27: 639054_2024_03_08_R_masked.nii.gz\n",
      "Processing file 28: 6532395_2025_01_23_L_masked.nii.gz\n",
      "Processing file 29: 654618_2024_12_18_L_masked.nii.gz\n",
      "Processing file 30: 654618_2024_12_18_R_masked.nii.gz\n",
      "Processing file 31: 661461_2025_03_19_R_masked.nii.gz\n",
      "Processing file 32: 6622465_2024_05_27_R_masked.nii.gz\n",
      "Processing file 33: 668695_2024_11_14_R_masked.nii.gz\n",
      "Processing file 34: 6710136_2024_12_08_R_masked.nii.gz\n",
      "Processing file 35: 6724015_2025_02_13_L_masked.nii.gz\n",
      "Processing file 36: 6724015_2025_02_13_R_masked.nii.gz\n",
      "Processing file 37: 67700034_2024_01_27_L_masked.nii.gz\n",
      "Processing file 38: 67700034_2024_01_27_R_masked.nii.gz\n",
      "Processing file 39: 679653_2024_07_01_L_masked.nii.gz\n",
      "Processing file 40: 68700050_2025_02_26_L_masked.nii.gz\n",
      "Processing file 41: 68700050_2025_02_26_R_masked.nii.gz\n",
      "Processing file 42: 68700244_2025_04_19_L_masked.nii.gz\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "input_folder = Path(r\"D:\\Kananat\\Data\\processing_More_data\\preprocessed\\Masked\")\n",
    "output_folder = r\"D:\\Kananat\\Data\\processing_More_data\\to_add_cropped\"\n",
    "\n",
    "i = 0\n",
    "for nii_file in input_folder.glob(\"*.nii*\"):\n",
    "    i += 1\n",
    "    print(f\"Processing file {i}: {nii_file.name}\")\n",
    "    output_path = Path(output_folder) / nii_file.name\n",
    "    processed_img = process_nifti(\n",
    "        input_path=str(nii_file),\n",
    "        output_path=str(output_path),\n",
    "        threshold=-250,\n",
    "        n=500,\n",
    "        m=256,\n",
    "        pad_value=-250,\n",
    "        clip_min=-250\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4b9c5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5011620_2025_02_13_L_masked.nii.gz 50-11620 L 20250213.nii.gz\n",
      "5011620_2025_02_13_R_masked.nii.gz 50-11620 R 20250213.nii.gz\n",
      "5218852_2016_05_26_L_masked.nii.gz 52-18852 L 20160526.nii.gz\n",
      "5218852_2016_05_26_R_masked.nii.gz 52-18852 R 20160526.nii.gz\n",
      "5237193_2016_04_05_L_masked.nii.gz 52-37193 L 20160405.nii.gz\n",
      "5237193_2016_04_05_R_masked.nii.gz 52-37193 R 20160405.nii.gz\n",
      "5425927_2016_04_24_L_masked.nii.gz 54-25927 L 20160424.nii.gz\n",
      "5425927_2016_04_24_R_masked.nii.gz 54-25927 R 20160424.nii.gz\n",
      "5450_2016_02_26_L_masked.nii.gz 54-50 L 20160226.nii.gz\n",
      "5450_2016_02_26_R_masked.nii.gz 54-50 R 20160226.nii.gz\n",
      "5630067_2024_01_31_R_masked.nii.gz 56-30067 R 20240131.nii.gz\n",
      "5724983_2016_07_02_L_masked.nii.gz 57-24983 L 20160702.nii.gz\n",
      "5724983_2016_07_02_R_masked.nii.gz 57-24983 R 20160702.nii.gz\n",
      "5734770_2016_01_17_L_masked.nii.gz 57-34770 L 20160117.nii.gz\n",
      "5734770_2016_01_17_R_masked.nii.gz 57-34770 R 20160117.nii.gz\n",
      "5841636_2016_01_29_L_masked.nii.gz 58-41636 L 20160129.nii.gz\n",
      "5841636_2016_01_29_R_masked.nii.gz 58-41636 R 20160129.nii.gz\n",
      "592326_2016_02_20_L_masked.nii.gz 59-2326 L 20160220.nii.gz\n",
      "592326_2016_02_20_R_masked.nii.gz 59-2326 R 20160220.nii.gz\n",
      "596269_2016_03_26_L_masked.nii.gz 59-6269 L 20160326.nii.gz\n",
      "596269_2016_03_26_R_masked.nii.gz 59-6269 R 20160326.nii.gz\n",
      "6034373_2024_10_08_L_masked.nii.gz 60-34373 L 20241008.nii.gz\n",
      "6034373_2024_10_08_R_masked.nii.gz 60-34373 R 20241008.nii.gz\n",
      "630010001_2024_05_27_L_masked.nii.gz 63-0010001 L 20240527.nii.gz\n",
      "630010001_2024_05_27_R_masked.nii.gz 63-0010001 R 20240527.nii.gz\n",
      "639054_2024_03_08_L_masked.nii.gz 63-9054 L 20240308.nii.gz\n",
      "639054_2024_03_08_R_masked.nii.gz 63-9054 R 20240308.nii.gz\n",
      "6532395_2025_01_23_L_masked.nii.gz 65-32395 L 20250123.nii.gz\n",
      "654618_2024_12_18_L_masked.nii.gz 65-4618 L 20241218.nii.gz\n",
      "654618_2024_12_18_R_masked.nii.gz 65-4618 R 20241218.nii.gz\n",
      "661461_2025_03_19_R_masked.nii.gz 66-1461 R 20250319.nii.gz\n",
      "6622465_2024_05_27_R_masked.nii.gz 66-22465 R 20240527.nii.gz\n",
      "668695_2024_11_14_R_masked.nii.gz 66-8695 R 20241114.nii.gz\n",
      "6710136_2024_12_08_R_masked.nii.gz 67-10136 R 20241208.nii.gz\n",
      "6724015_2025_02_13_L_masked.nii.gz 67-24015 L 20250213.nii.gz\n",
      "6724015_2025_02_13_R_masked.nii.gz 67-24015 R 20250213.nii.gz\n",
      "67700034_2024_01_27_L_masked.nii.gz 67-700034 L 20240127.nii.gz\n",
      "67700034_2024_01_27_R_masked.nii.gz 67-700034 R 20240127.nii.gz\n",
      "679653_2024_07_01_L_masked.nii.gz 67-9653 L 20240701.nii.gz\n",
      "68700050_2025_02_26_L_masked.nii.gz 68-700050 L 20250226.nii.gz\n",
      "68700050_2025_02_26_R_masked.nii.gz 68-700050 R 20250226.nii.gz\n",
      "68700244_2025_04_19_L_masked.nii.gz 68-700244 L 20250419.nii.gz\n"
     ]
    }
   ],
   "source": [
    "input_folder = Path(r\"D:\\Kananat\\Data\\processing_More_data\\to_add_cropped\")\n",
    "\n",
    "for file in input_folder.glob(\"*.nii.gz\"):\n",
    "    parts = file.name.split(\"_\")\n",
    "    new_name = f\"{parts[0][:2]}-{parts[0][2:]} {parts[4]} {parts[1]}{parts[2]}{parts[3]}.nii.gz\"\n",
    "    new_path = file.parent / new_name\n",
    "    print(file.name, new_name)\n",
    "    file.rename(new_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2dmodelGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
