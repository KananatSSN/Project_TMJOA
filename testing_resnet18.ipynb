{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83ff199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock3D(nn.Module):\n",
    "    \"\"\"Basic 3D residual block\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, dropout_rate=0.0):\n",
    "        super(BasicBlock3D, self).__init__()\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm3d(in_channels)\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, \n",
    "                              stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, \n",
    "                              stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.dropout = nn.Dropout3d(dropout_rate) if dropout_rate > 0 else None\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, out_channels, kernel_size=1, \n",
    "                         stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(x), negative_slope=0.01)\n",
    "        out = self.conv1(out)\n",
    "        out = F.leaky_relu(self.bn2(out), negative_slope=0.01)\n",
    "        \n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "            \n",
    "        out = self.conv2(out)\n",
    "        out += self.shortcut(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ModifiedWideResNet3D(nn.Module):\n",
    "    \"\"\"Modified WideResNet3D for larger input and binary classification\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=(64, 64, 64), width=2, num_classes=2, dropout_rate=0.3):\n",
    "        super(ModifiedWideResNet3D, self).__init__()\n",
    "        \n",
    "        k = width\n",
    "        nChannels = [16, 16*k, 32*k, 64*k, 128*k]\n",
    "        \n",
    "        # Initial convolution - downsample immediately for large inputs\n",
    "        self.conv1 = nn.Conv3d(1, nChannels[0], kernel_size=7, stride=2, \n",
    "                              padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(nChannels[0])\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Residual blocks with progressive downsampling\n",
    "        self.block1 = self._make_layer(nChannels[0], nChannels[1], 2, stride=1, dropout_rate=dropout_rate)\n",
    "        self.block2 = self._make_layer(nChannels[1], nChannels[2], 2, stride=2, dropout_rate=dropout_rate)\n",
    "        self.block3 = self._make_layer(nChannels[2], nChannels[3], 2, stride=2, dropout_rate=dropout_rate)\n",
    "        self.block4 = self._make_layer(nChannels[3], nChannels[4], 2, stride=2, dropout_rate=dropout_rate)\n",
    "        \n",
    "        # Final layers\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(nChannels[4], num_classes)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride, dropout_rate):\n",
    "        layers = []\n",
    "        layers.append(BasicBlock3D(in_channels, out_channels, stride, dropout_rate))\n",
    "        \n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(BasicBlock3D(out_channels, out_channels, 1, dropout_rate))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.leaky_relu(self.bn1(x), negative_slope=0.01)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        \n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=1,\n",
    "        bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, 2)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(512, 2)  # Binary classification\n",
    "\n",
    "        # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(self.inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(planes)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def resnet18():\n",
    "    \"\"\"3D ResNet-18 for binary classification\"\"\"\n",
    "    return ResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc3020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModifiedWideResNet3D(\n",
       "  (conv1): Conv3d(1, 16, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (block1): Sequential(\n",
       "    (0): BasicBlock3D(\n",
       "      (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (dropout): Dropout3d(p=0.3, inplace=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock3D(\n",
       "      (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (dropout): Dropout3d(p=0.3, inplace=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): BasicBlock3D(\n",
       "      (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (dropout): Dropout3d(p=0.3, inplace=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock3D(\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (dropout): Dropout3d(p=0.3, inplace=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): BasicBlock3D(\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (dropout): Dropout3d(p=0.3, inplace=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock3D(\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (dropout): Dropout3d(p=0.3, inplace=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (block4): Sequential(\n",
       "    (0): BasicBlock3D(\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (dropout): Dropout3d(p=0.3, inplace=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock3D(\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (dropout): Dropout3d(p=0.3, inplace=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (adaptive_pool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_path = r\"c:\\Users\\kanan\\Downloads\\erosion_3D\\content\\checkpoints\\best_model.pth\"\n",
    "image_size = (254, 254, 254)\n",
    "\n",
    "# Create model instance\n",
    "model = ModifiedWideResNet3D(\n",
    "    input_size=image_size,\n",
    "    width=2,\n",
    "    num_classes=2\n",
    ")\n",
    "\n",
    "# Load the saved weights\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04868644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "def predict_single_nifti(model, nifti_path, target_size=(64, 64, 64), device=None):\n",
    "    \"\"\"\n",
    "    Predict a single NIfTI image using the trained model\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        nifti_path: Path to the .nii.gz file\n",
    "        target_size: Target size to resize image to (depth, height, width)\n",
    "        device: Device to run inference on\n",
    "    \n",
    "    Returns:\n",
    "        prediction: Predicted class (0 or 1)\n",
    "        confidence: Confidence score\n",
    "        probabilities: Raw probabilities for both classes\n",
    "    \"\"\"\n",
    "    \n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Ensure model is in eval mode\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Load and preprocess the image (same as your dataset)\n",
    "    image = load_and_preprocess_nifti(nifti_path, target_size)\n",
    "    \n",
    "    # Convert to tensor and add batch dimension\n",
    "    image_tensor = torch.from_numpy(image).float().unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, D, H, W)\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        predicted = torch.argmax(probabilities, dim=1)\n",
    "        confidence = probabilities[0, predicted].item()\n",
    "    \n",
    "    return predicted.item(), confidence, probabilities[0].cpu().numpy()\n",
    "\n",
    "\n",
    "def load_and_preprocess_nifti(filepath, target_size=(64, 64, 64)):\n",
    "    \"\"\"\n",
    "    Load and preprocess a single NIfTI file\n",
    "    This replicates the preprocessing logic from your dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load NIfTI image\n",
    "    nii_img = nib.load(filepath)\n",
    "    image = nii_img.get_fdata()\n",
    "    \n",
    "    # Handle different input dimensions\n",
    "    if len(image.shape) == 4:\n",
    "        # If 4D, take the first volume\n",
    "        image = image[:, :, :, 0]\n",
    "    \n",
    "    # Normalize to [0, 1] (same as your _normalize_image method)\n",
    "    image = normalize_image(image)\n",
    "    \n",
    "    # Resize if needed (same as your _resize_image method)\n",
    "    if image.shape != target_size:\n",
    "        image = resize_image(image, target_size)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"Normalize image to [0, 1] range - copied from your dataset\"\"\"\n",
    "    # Remove NaN and infinity values\n",
    "    image = np.nan_to_num(image, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    if max_val > min_val:\n",
    "        image = (image - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        image = np.zeros_like(image)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def resize_image(image, target_size):\n",
    "    \"\"\"Resize image using trilinear interpolation - copied from your dataset\"\"\"\n",
    "    # Convert to tensor for interpolation\n",
    "    image_tensor = torch.from_numpy(image).float().unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # Resize using trilinear interpolation\n",
    "    resized = F.interpolate(\n",
    "        image_tensor,\n",
    "        size=target_size,\n",
    "        mode='trilinear',\n",
    "        align_corners=False\n",
    "    )\n",
    "    \n",
    "    return resized.squeeze(0).squeeze(0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336c2a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0, Confidence: 0.9060, Probabilities: [0.9059875  0.09401254]\n"
     ]
    }
   ],
   "source": [
    "image_path = r'd:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\test\\0\\57-36050 L_adjustedBG.nii.gz'\n",
    "\n",
    "prediction, confidence, probabilities = predict_single_nifti(\n",
    "    model, \n",
    "    image_path, \n",
    "    target_size=image_size  # Use the same target_size as training\n",
    ")\n",
    "\n",
    "print(f\"Predicted class: {prediction}, Confidence: {confidence:.4f}, Probabilities: {probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d9ec928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\49-18165 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.5304, Probabilities: [0.53043586 0.46956405]\n",
      "49-18165 R 0 0 0.5304358601570129\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\50-30909 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.5039, Probabilities: [0.5039019  0.49609813]\n",
      "50-30909 R 0 0 0.5039018988609314\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\56-18364 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9214, Probabilities: [0.07861178 0.92138827]\n",
      "56-18364 L 0 1 0.9213882684707642\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\58-42016 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.8477, Probabilities: [0.15227446 0.8477256 ]\n",
      "58-42016 L 0 1 0.8477255702018738\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\58-42016 R_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.7095, Probabilities: [0.29048866 0.70951134]\n",
      "58-42016 R 0 1 0.7095113396644592\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\59-27051 L_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.5506, Probabilities: [0.5506082 0.4493917]\n",
      "59-27051 L 0 0 0.550608217716217\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\59-27051 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.5548, Probabilities: [0.5547834 0.4452166]\n",
      "59-27051 R 0 0 0.5547834038734436\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\59-6269 L_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.7897, Probabilities: [0.7897163 0.2102837]\n",
      "59-6269 L 0 0 0.7897163033485413\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\60-701005 R 2021_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9191, Probabilities: [0.08091256 0.91908747]\n",
      "60-701005 R 2021 0 1 0.9190874695777893\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\61-13344 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.6318, Probabilities: [0.6318277  0.36817226]\n",
      "61-13344 R 0 0 0.631827712059021\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\61-14198 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.5079, Probabilities: [0.5079278 0.4920722]\n",
      "61-14198 R 0 0 0.5079277753829956\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\61-32062 L_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.5969, Probabilities: [0.59688145 0.40311855]\n",
      "61-32062 L 0 0 0.5968814492225647\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\61-32062 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.8930, Probabilities: [0.893047   0.10695309]\n",
      "61-32062 R 0 0 0.8930469751358032\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\61-33141 L_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.6255, Probabilities: [0.62546086 0.37453914]\n",
      "61-33141 L 0 0 0.6254608631134033\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\61-33141 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.6145, Probabilities: [0.6145168  0.38548315]\n",
      "61-33141 R 0 0 0.6145167946815491\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\61-700101 L_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.6747, Probabilities: [0.6747038  0.32529625]\n",
      "61-700101 L 0 0 0.6747037768363953\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\61-700101 R_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.7458, Probabilities: [0.25423038 0.74576956]\n",
      "61-700101 R 0 1 0.7457695603370667\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\62-34626 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.6336, Probabilities: [0.6335776  0.36642236]\n",
      "62-34626 R 0 0 0.6335775852203369\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\63-2829 L_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.5873, Probabilities: [0.58728576 0.41271418]\n",
      "63-2829 L 0 0 0.5872857570648193\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\63-700385 L_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.8700, Probabilities: [0.8700256  0.12997444]\n",
      "63-700385 L 0 0 0.8700255751609802\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\64-700178 L_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.9514, Probabilities: [0.9513753  0.04862468]\n",
      "64-700178 L 0 0 0.9513753056526184\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\64-7881 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.6947, Probabilities: [0.69467413 0.30532584]\n",
      "64-7881 R 0 0 0.6946741342544556\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\65-20101 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.9062, Probabilities: [0.90624577 0.09375418]\n",
      "65-20101 R 0 0 0.906245768070221\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\65-24090 L 2023 11 17_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.5384, Probabilities: [0.53839046 0.46160954]\n",
      "65-24090 L 2023 11 17 0 0 0.5383904576301575\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\65-24090 R 2023 11 17_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.5859, Probabilities: [0.58592933 0.41407067]\n",
      "65-24090 R 2023 11 17 0 0 0.5859293341636658\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\65-24090 R 2023 11 29_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.5596, Probabilities: [0.55958104 0.440419  ]\n",
      "65-24090 R 2023 11 29 0 0 0.5595810413360596\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\65-25886 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.9740, Probabilities: [0.9740297  0.02597027]\n",
      "65-25886 R 0 0 0.9740297198295593\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\65-27050 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.5818, Probabilities: [0.5817546  0.41824538]\n",
      "65-27050 R 0 0 0.5817546248435974\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\66-13889 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.6864, Probabilities: [0.68637437 0.31362563]\n",
      "66-13889 R 0 0 0.6863743662834167\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\66-18213 L_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.6915, Probabilities: [0.6915323 0.3084677]\n",
      "66-18213 L 0 0 0.6915323138237\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\0\\66-18213 R_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.8815, Probabilities: [0.11847655 0.88152343]\n",
      "66-18213 R 0 1 0.8815234303474426\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\47-16872 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9242, Probabilities: [0.07577241 0.92422754]\n",
      "47-16872 L 1 1 0.9242275357246399\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\47-16872 R_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.6662, Probabilities: [0.33378744 0.6662126 ]\n",
      "47-16872 R 1 1 0.6662126183509827\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\49-18165 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9359, Probabilities: [0.06409293 0.93590707]\n",
      "49-18165 L 1 1 0.9359070658683777\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\49-3614 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9288, Probabilities: [0.07116782 0.9288321 ]\n",
      "49-3614 L 1 1 0.9288321137428284\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\49-3614 R_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.8877, Probabilities: [0.11231221 0.8876878 ]\n",
      "49-3614 R 1 1 0.8876878023147583\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\52-15242 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.8840, Probabilities: [0.11604372 0.88395625]\n",
      "52-15242 L 1 1 0.883956253528595\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\52-15242 R_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.9885, Probabilities: [0.9884821  0.01151787]\n",
      "52-15242 R 1 0 0.9884821176528931\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\56-18364 R_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9621, Probabilities: [0.03791166 0.96208835]\n",
      "56-18364 R 1 1 0.9620883464813232\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\56-27847 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.7100, Probabilities: [0.29001698 0.709983  ]\n",
      "56-27847 L 1 1 0.7099829912185669\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\56-27847 R_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9450, Probabilities: [0.05503877 0.94496125]\n",
      "56-27847 R 1 1 0.9449612498283386\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\58-9834 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9267, Probabilities: [0.07329389 0.92670614]\n",
      "58-9834 L 1 1 0.9267061352729797\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\58-9834 R_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.6680, Probabilities: [0.33198795 0.668012  ]\n",
      "58-9834 R 1 1 0.6680120229721069\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\59-24008 L_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.5926, Probabilities: [0.59259844 0.40740153]\n",
      "59-24008 L 1 0 0.5925984382629395\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\60-24908 L 2017_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9277, Probabilities: [0.07234863 0.92765135]\n",
      "60-24908 L 2017 1 1 0.9276513457298279\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\60-24908 L 2023_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.8097, Probabilities: [0.1902502 0.8097498]\n",
      "60-24908 L 2023 1 1 0.8097497820854187\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\60-24908 R 2017_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.7638, Probabilities: [0.23619398 0.763806  ]\n",
      "60-24908 R 2017 1 1 0.7638059854507446\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\60-24908 R 2023_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.6936, Probabilities: [0.30641922 0.69358075]\n",
      "60-24908 R 2023 1 1 0.6935807466506958\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\60-33597 L 2017_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.7438, Probabilities: [0.2562053  0.74379474]\n",
      "60-33597 L 2017 1 1 0.7437947392463684\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\60-33597 L 2019 03 11_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9127, Probabilities: [0.08729031 0.9127097 ]\n",
      "60-33597 L 2019 03 11 1 1 0.9127097129821777\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\60-33597 L 2019 09 02_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.8985, Probabilities: [0.10151666 0.89848334]\n",
      "60-33597 L 2019 09 02 1 1 0.8984833359718323\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\60-38868 R_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9582, Probabilities: [0.04178468 0.95821536]\n",
      "60-38868 R 1 1 0.9582153558731079\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\60-39505 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.5623, Probabilities: [0.43768856 0.5623114 ]\n",
      "60-39505 L 1 1 0.5623114109039307\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\60-39505 R_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.7406, Probabilities: [0.25939757 0.74060243]\n",
      "60-39505 R 1 1 0.740602433681488\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\60-701005 L 2017_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.7819, Probabilities: [0.21812093 0.781879  ]\n",
      "60-701005 L 2017 1 1 0.7818790078163147\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\60-701005 L 2021_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.8416, Probabilities: [0.15840562 0.8415944 ]\n",
      "60-701005 L 2021 1 1 0.841594398021698\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\60-701005 R 2017_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.8726, Probabilities: [0.12739947 0.8726005 ]\n",
      "60-701005 R 2017 1 1 0.8726004958152771\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\61-13344 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.8182, Probabilities: [0.18175526 0.8182447 ]\n",
      "61-13344 L 1 1 0.8182446956634521\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\61-14198 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.7776, Probabilities: [0.22240424 0.77759576]\n",
      "61-14198 L 1 1 0.7775957584381104\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\61-16015 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9377, Probabilities: [0.06228224 0.93771774]\n",
      "61-16015 L 1 1 0.9377177357673645\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\61-16015 R 2022_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9315, Probabilities: [0.068543   0.93145704]\n",
      "61-16015 R 2022 1 1 0.9314570426940918\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\61-5225 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9281, Probabilities: [0.07186913 0.92813087]\n",
      "61-5225 L 1 1 0.9281308650970459\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\62-13410 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.6079, Probabilities: [0.39214417 0.6078558 ]\n",
      "62-13410 L 1 1 0.6078557968139648\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\62-13410 R_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9080, Probabilities: [0.09199287 0.9080072 ]\n",
      "62-13410 R 1 1 0.9080072045326233\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\62-24379 R_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.5271, Probabilities: [0.47294208 0.52705795]\n",
      "62-24379 R 1 1 0.527057945728302\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\63-700385 R_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9109, Probabilities: [0.08912443 0.91087556]\n",
      "63-700385 R 1 1 0.9108755588531494\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\64-7881 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9260, Probabilities: [0.07401624 0.9259837 ]\n",
      "64-7881 L 1 1 0.925983726978302\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\65-11496 L_adjustedBG.nii.gz, Predicted class: 0, Confidence: 0.6180, Probabilities: [0.61803234 0.38196766]\n",
      "65-11496 L 1 0 0.6180323362350464\n",
      "File: D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val\\1\\65-20101 L_adjustedBG.nii.gz, Predicted class: 1, Confidence: 0.9176, Probabilities: [0.08242067 0.9175794 ]\n",
      "65-20101 L 1 1 0.9175794124603271\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "data_dir = r'D:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\val'\n",
    "\n",
    "result_from_images = []\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.nii') or file.endswith('.nii.gz'):\n",
    "            real_label = int(root.split(os.sep)[-1])  # Get the real label from the folder name\n",
    "            file_path = os.path.join(root, file)\n",
    "            patient_id = file.split('_')[0]\n",
    "            \n",
    "            predict_label, confidence, probabilities = predict_single_nifti(\n",
    "                model, \n",
    "                file_path, \n",
    "                target_size=image_size  # Use the same target_size as training\n",
    "            )\n",
    "            print(f\"File: {file_path}, Predicted class: {predict_label}, Confidence: {confidence:.4f}, Probabilities: {probabilities}\")\n",
    "\n",
    "            print(patient_id, real_label, predict_label, confidence)\n",
    "            result_from_images.append((patient_id, real_label, predict_label, confidence))\n",
    "\n",
    "save_path = rf\"{data_dir}\\predictions.txt\"\n",
    "with open(save_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write data\n",
    "    for patient_id ,real, predicted_class, conf in result_from_images:\n",
    "        writer.writerow([patient_id ,real, predicted_class, conf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f11ff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "csv_file = r\"d:\\Kananat\\Data\\training_dataset_3D\\training_dataset_erosion\\test\\predictions.txt\"\n",
    "\n",
    "with open(csv_file, 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    data = list(csv_reader)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "253638a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "correct = sum(1 for row in data if int(row[1]) == int(row[2]))\n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2c654fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "print(27/39)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2dmodelGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
