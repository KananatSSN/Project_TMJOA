{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "def file_to_ndarray(filepath):\n",
    "    # Check the file extension\n",
    "    _, file_extension = os.path.splitext(filepath)\n",
    "    \n",
    "    try:\n",
    "        if file_extension in ['.nii', '.nii.gz']:  # Handle gzipped or regular NIfTI files\n",
    "            # Load the NIfTI file\n",
    "            nii_img = nib.load(filepath)\n",
    "            # Convert to ndarray\n",
    "            data = nii_img.get_fdata()\n",
    "            #print(f\"Loaded NIfTI file: {filepath}\")\n",
    "        else:\n",
    "            print(\"Unsupported file format.\")\n",
    "            return None\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_histogram(ndarray):\n",
    "    \n",
    "    flat_array = ndarray.flatten()\n",
    "\n",
    "    # Define the bin edges from -4000 to 4000 with a bin size of 10\n",
    "    bins = np.arange(-4000, 4001, 10)  # 2001 to include the endpoint 2000 in the last bin\n",
    "\n",
    "    # Compute histogram\n",
    "    histogram_values, bin_edges = np.histogram(flat_array, bins=bins)\n",
    "\n",
    "    # Convert histogram values to list\n",
    "    histogram_list = histogram_values.tolist()\n",
    "\n",
    "    return histogram_list, bin_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def append_to_csv(file_path, file_name, list_to_append):\n",
    "    # Open the file in append mode\n",
    "\n",
    "    list_to_append = [file_name] + list_to_append\n",
    "\n",
    "    with open(file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write the list as the last row in the CSV\n",
    "        writer.writerow(list_to_append)\n",
    "        #print(\"Successfully to the CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_csv_as_dataframe(filepath):\n",
    "    # Read the CSV file without headers\n",
    "    df = pd.read_csv(filepath, header=None)\n",
    "\n",
    "    # Use the first column as the header\n",
    "    headers = df.iloc[:, 0]  # Extract the first column as headers\n",
    "    df = df.iloc[:, 1:]      # Remove the first column from the df\n",
    "    df = df.T\n",
    "    df.columns = headers     # Set the extracted column as headers\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_columns_of_dataframe(df, x_coords):\n",
    "    # Check if the length of x_coords matches the number of rows in the DataFrame\n",
    "    if len(x_coords) != len(df):\n",
    "        raise ValueError(\"Length of x_coords must match the number of rows in the DataFrame\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Loop through each column in the DataFrame and plot\n",
    "    for column in df.columns:\n",
    "        plt.plot(x_coords, df[column], label=f'Column: {column}')\n",
    "\n",
    "    plt.title('Voxels intensity distribution')\n",
    "    plt.xlabel('Voxels intensity')\n",
    "    plt.ylabel('Voxels count')\n",
    "    #plt.legend()\n",
    "    #plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 144 .nii files in the C:\\Users\\acer\\Desktop\\Project_TMJOA\\Data\\Open access data\\Baseline_fixed\n",
      "[Processing 1 out of 144]\n",
      "[Processing 2 out of 144]\n",
      "[Processing 3 out of 144]\n",
      "[Processing 4 out of 144]\n",
      "[Processing 5 out of 144]\n",
      "[Processing 6 out of 144]\n",
      "[Processing 7 out of 144]\n",
      "[Processing 8 out of 144]\n",
      "[Processing 9 out of 144]\n",
      "[Processing 10 out of 144]\n",
      "[Processing 11 out of 144]\n",
      "[Processing 12 out of 144]\n",
      "[Processing 13 out of 144]\n",
      "[Processing 14 out of 144]\n",
      "[Processing 15 out of 144]\n",
      "[Processing 16 out of 144]\n",
      "[Processing 17 out of 144]\n",
      "[Processing 18 out of 144]\n",
      "[Processing 19 out of 144]\n",
      "[Processing 20 out of 144]\n",
      "[Processing 21 out of 144]\n",
      "[Processing 22 out of 144]\n",
      "[Processing 23 out of 144]\n",
      "[Processing 24 out of 144]\n",
      "[Processing 25 out of 144]\n",
      "[Processing 26 out of 144]\n",
      "[Processing 27 out of 144]\n",
      "[Processing 28 out of 144]\n",
      "[Processing 29 out of 144]\n",
      "[Processing 30 out of 144]\n",
      "[Processing 31 out of 144]\n",
      "[Processing 32 out of 144]\n",
      "[Processing 33 out of 144]\n",
      "[Processing 34 out of 144]\n",
      "[Processing 35 out of 144]\n",
      "[Processing 36 out of 144]\n",
      "[Processing 37 out of 144]\n",
      "[Processing 38 out of 144]\n",
      "[Processing 39 out of 144]\n",
      "[Processing 40 out of 144]\n",
      "[Processing 41 out of 144]\n",
      "[Processing 42 out of 144]\n",
      "[Processing 43 out of 144]\n",
      "[Processing 44 out of 144]\n",
      "[Processing 45 out of 144]\n",
      "[Processing 46 out of 144]\n",
      "[Processing 47 out of 144]\n",
      "[Processing 48 out of 144]\n",
      "[Processing 49 out of 144]\n",
      "[Processing 50 out of 144]\n",
      "[Processing 51 out of 144]\n",
      "[Processing 52 out of 144]\n",
      "[Processing 53 out of 144]\n",
      "[Processing 54 out of 144]\n",
      "[Processing 55 out of 144]\n",
      "[Processing 56 out of 144]\n",
      "[Processing 57 out of 144]\n",
      "[Processing 58 out of 144]\n",
      "[Processing 59 out of 144]\n",
      "[Processing 60 out of 144]\n",
      "[Processing 61 out of 144]\n",
      "[Processing 62 out of 144]\n",
      "[Processing 63 out of 144]\n",
      "[Processing 64 out of 144]\n",
      "[Processing 65 out of 144]\n",
      "[Processing 66 out of 144]\n",
      "[Processing 67 out of 144]\n",
      "[Processing 68 out of 144]\n",
      "[Processing 69 out of 144]\n",
      "[Processing 70 out of 144]\n",
      "[Processing 71 out of 144]\n",
      "[Processing 72 out of 144]\n",
      "[Processing 73 out of 144]\n",
      "[Processing 74 out of 144]\n",
      "[Processing 75 out of 144]\n",
      "[Processing 76 out of 144]\n",
      "[Processing 77 out of 144]\n",
      "[Processing 78 out of 144]\n",
      "[Processing 79 out of 144]\n",
      "[Processing 80 out of 144]\n",
      "[Processing 81 out of 144]\n",
      "[Processing 82 out of 144]\n",
      "[Processing 83 out of 144]\n",
      "[Processing 84 out of 144]\n",
      "[Processing 85 out of 144]\n",
      "[Processing 86 out of 144]\n",
      "[Processing 87 out of 144]\n",
      "[Processing 88 out of 144]\n",
      "[Processing 89 out of 144]\n",
      "[Processing 90 out of 144]\n",
      "[Processing 91 out of 144]\n",
      "[Processing 92 out of 144]\n",
      "[Processing 93 out of 144]\n",
      "[Processing 94 out of 144]\n",
      "[Processing 95 out of 144]\n",
      "[Processing 96 out of 144]\n",
      "[Processing 97 out of 144]\n",
      "[Processing 98 out of 144]\n",
      "[Processing 99 out of 144]\n",
      "[Processing 100 out of 144]\n",
      "[Processing 101 out of 144]\n",
      "[Processing 102 out of 144]\n",
      "[Processing 103 out of 144]\n",
      "[Processing 104 out of 144]\n",
      "[Processing 105 out of 144]\n",
      "[Processing 106 out of 144]\n",
      "[Processing 107 out of 144]\n",
      "[Processing 108 out of 144]\n",
      "[Processing 109 out of 144]\n",
      "[Processing 110 out of 144]\n",
      "[Processing 111 out of 144]\n",
      "[Processing 112 out of 144]\n",
      "[Processing 113 out of 144]\n",
      "[Processing 114 out of 144]\n",
      "[Processing 115 out of 144]\n",
      "[Processing 116 out of 144]\n",
      "[Processing 117 out of 144]\n",
      "[Processing 118 out of 144]\n",
      "[Processing 119 out of 144]\n",
      "[Processing 120 out of 144]\n",
      "[Processing 121 out of 144]\n",
      "[Processing 122 out of 144]\n",
      "[Processing 123 out of 144]\n",
      "[Processing 124 out of 144]\n",
      "[Processing 125 out of 144]\n",
      "[Processing 126 out of 144]\n",
      "[Processing 127 out of 144]\n",
      "[Processing 128 out of 144]\n",
      "[Processing 129 out of 144]\n",
      "[Processing 130 out of 144]\n",
      "[Processing 131 out of 144]\n",
      "[Processing 132 out of 144]\n",
      "[Processing 133 out of 144]\n",
      "[Processing 134 out of 144]\n",
      "[Processing 135 out of 144]\n",
      "[Processing 136 out of 144]\n",
      "[Processing 137 out of 144]\n",
      "[Processing 138 out of 144]\n",
      "[Processing 139 out of 144]\n",
      "[Processing 140 out of 144]\n",
      "[Processing 141 out of 144]\n",
      "[Processing 142 out of 144]\n",
      "[Processing 143 out of 144]\n",
      "[Processing 144 out of 144]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory path where the .nii files are located\n",
    "volume_folder = r\"C:\\Users\\acer\\Desktop\\Project_TMJOA\\Data\\Open access data\\Baseline_fixed\"  # Replace with your actual directory path\n",
    "csv_path = rf\"{volume_folder}\\volxel_intensity.csv\"\n",
    "\n",
    "nii_count = len([filename for filename in os.listdir(volume_folder) if filename.endswith('.nii.gz')])\n",
    "print(f\"There are {nii_count} .nii files in the {volume_folder}\")\n",
    "\n",
    "progress_count = 0\n",
    "\n",
    "files = sorted(os.listdir(volume_folder))\n",
    "\n",
    "# Loop through each file in the directory\n",
    "error_log = []\n",
    "for filename in files:\n",
    "\n",
    "    if filename.endswith('.nii.gz'):\n",
    "        \n",
    "        # Progress bar\n",
    "        progress_count += 1\n",
    "        print(f\"[Processing {progress_count} out of {nii_count}]\")\n",
    "\n",
    "        try:\n",
    "            # Full path to the file\n",
    "            file_path = os.path.join(volume_folder, filename)\n",
    "            #print(f\"Processing file: {filename}\")\n",
    "\n",
    "            # Read .nii file\n",
    "            nii_img = nib.load(file_path)\n",
    "            data = nii_img.get_fdata()\n",
    "\n",
    "            # # Compute histogram\n",
    "            histogram_values, bin_edges = compute_histogram(data)\n",
    "\n",
    "            # # Write to csv\n",
    "            append_to_csv(csv_path, filename, histogram_values)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            error_log.append(filename)\n",
    "\n",
    "for file in error_log:\n",
    "    print(file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2dmodelGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
