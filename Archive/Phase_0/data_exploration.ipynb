{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_subfolders(directory,depth_limit):\n",
    "    \"\"\" Counts subfolders within the first two layers of the given directory \"\"\"\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # Calculate depth by comparing the root and the directory path\n",
    "        depth = root[len(directory):].count(os.sep)\n",
    "        if depth < depth_limit:  # Only count if the depth is less than 2\n",
    "            count += len(dirs)\n",
    "    return count\n",
    "\n",
    "# Use a raw string for the directory path\n",
    "directory_path = r\"C:\\Users\\acer\\Desktop\\Project\\Data\"\n",
    "depth = 2\n",
    "total_subfolders = count_subfolders(directory_path,depth)\n",
    "print(f\"Total subfolders within two layers: {total_subfolders}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nrrd\n",
    "\n",
    "# Reading an NRRD file\n",
    "data, header = nrrd.read(r\"C:\\Users\\acer\\Desktop\\Project\\Data\\57-2014\\Segmentation\\474881R.nrrd\")\n",
    "\n",
    "# Accessing data and header information\n",
    "print(data.shape)\n",
    "print(header)\n",
    "\n",
    "# Writing to an NRRD file\n",
    "nrrd.write('new_file.nrrd', data, header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading an NRRD file\n",
    "data, header = nrrd.read(r\"C:\\Users\\acer\\Desktop\\Project\\Data\\57-2014\\Segmentation\\Segmentation.seg.nrrd\")\n",
    "\n",
    "# Accessing data and header information\n",
    "print(data.shape)\n",
    "print(header)\n",
    "\n",
    "# Writing to an NRRD file\n",
    "nrrd.write('new_file.nrrd', data, header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nrrd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_nrrd_slices(file_paths, slice_index, axis=0):\n",
    "    \"\"\"\n",
    "    Display the same specific slice from multiple 3D NRRD images side by side.\n",
    "\n",
    "    Parameters:\n",
    "    - file_paths: list of str, paths to the NRRD files.\n",
    "    - slice_index: int, index of the slice to display.\n",
    "    - axis: int, dimension along which to slice the volumes (0, 1, or 2).\n",
    "            0 - Axial (default), 1 - Coronal, 2 - Sagittal.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Loop through each file\n",
    "    for i, path in enumerate(file_paths):\n",
    "        # Read the NRRD file (data and header)\n",
    "        data, header = nrrd.read(path)\n",
    "\n",
    "        # Select the slice based on the specified axis\n",
    "        if axis == 0:\n",
    "            slice_data = data[slice_index, :, :]\n",
    "        elif axis == 1:\n",
    "            slice_data = data[:, slice_index, :]\n",
    "        elif axis == 2:\n",
    "            slice_data = data[:, :, slice_index]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid axis. Axis must be 0, 1, or 2.\")\n",
    "        \n",
    "        # Plotting the slice using matplotlib\n",
    "        ax = plt.subplot(1, len(file_paths), i + 1)\n",
    "        ax.imshow(slice_data, cmap='gray')  # Use grayscale color map for better visualization\n",
    "        ax.title.set_text(f'File {i+1}: Slice {slice_index} along axis {axis}')\n",
    "        ax.axis('off')  # Turn off axis numbers and ticks\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [r\"C:\\Users\\acer\\Desktop\\Data\\57-2014\\Segmentation\\474881R.nrrd\", r\"C:\\Users\\acer\\Desktop\\Data\\57-2014\\Segmentation\\Segmentation.seg.nrrd\"]\n",
    "slice_indices = 310  # Assuming you want the same slice index for both\n",
    "axes = 2  # Both axial slices\n",
    "\n",
    "display_nrrd_slices(file_paths, slice_indices, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\acer\\Desktop\\Data\\57-2014\\Segmentation\\474881R.nrrd\"\n",
    "data, header = nrrd.read(file_path)\n",
    "slice_data = data[:, :, 310]\n",
    "\n",
    "plt.imshow(slice_data, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_data[slice_data != -1306] = 0\n",
    "plt.imshow(slice_data, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\acer\\Desktop\\Data\\57-2014\\Segmentation\\474881R.nrrd\"\n",
    "data, header = nrrd.read(file_path)\n",
    "slice_data = data[:, :, 310]\n",
    "\n",
    "slice_data[slice_data < -700] = -700\n",
    "slice_data[slice_data > -225] = -700\n",
    "\n",
    "# Rescale the values to the range [0, 255]\n",
    "rescaled_array = 255 * (slice_data + 700) / (-225 + 700)\n",
    "\n",
    "plt.imshow(rescaled_array, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\acer\\Desktop\\Data\\57-2014\\Segmentation\\474881R.nrrd\"\n",
    "data, header = nrrd.read(file_path)\n",
    "slice_data = data[:, :, 310]\n",
    "\n",
    "slice_data[slice_data < -225] = 0\n",
    "slice_data[slice_data > 500] = 0\n",
    "\n",
    "min_val = np.min(slice_data)\n",
    "max_val = np.max(slice_data)\n",
    "\n",
    "# Rescale the values to the range [0, 255]\n",
    "rescaled_array = 255 * (slice_data - min_val) / (max_val - min_val)\n",
    "\n",
    "plt.imshow(slice_data, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\acer\\Desktop\\Data\\57-2014\\Segmentation\\474881R.nrrd\"\n",
    "data, header = nrrd.read(file_path)\n",
    "slice_data = data[:, :, 310]\n",
    "\n",
    "slice_data[slice_data < 500] = 500\n",
    "\n",
    "# Rescale the values to the range [0, 255]\n",
    "rescaled_array = 255 * (slice_data - 500) / (1400 - 500)\n",
    "\n",
    "plt.imshow(slice_data, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\acer\\Desktop\\Data\\57-2014\\Segmentation\\474881R.nrrd\"\n",
    "data, header = nrrd.read(file_path)\n",
    "slice_data = data[:, :, 310]\n",
    "\n",
    "plt.imshow(slice_data, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nrrd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_pixel_intensity_distribution(nrrd_file_path):\n",
    "    # Load the NRRD file\n",
    "    data, header = nrrd.read(nrrd_file_path)\n",
    "    \n",
    "    # data is a numpy array with shape (slices, height, width) for a 3D volume\n",
    "    # Flatten the data to get a 1D array of all pixel values across all slices\n",
    "    all_pixels = data.flatten()\n",
    "\n",
    "    # Plot histogram of pixel intensities\n",
    "    filtered_array = all_pixels[all_pixels != -1306]\n",
    "    plt.hist(filtered_array, bins=100)\n",
    "    plt.xlabel('Pixel Intensity')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "nrrd_file_path = r\"C:\\Users\\acer\\Desktop\\Data\\57-2014\\Segmentation\\474881R.nrrd\"\n",
    "plot_pixel_intensity_distribution(nrrd_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all dimension and pixel intensity distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "\n",
    "def list_nii_dimensions(directory):\n",
    "    # List to hold file names and dimensions\n",
    "    file_dimensions = []\n",
    "\n",
    "    # Loop through each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.nii'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                # Load the image file\n",
    "                img = nib.load(file_path)\n",
    "                # Get the dimensions of the image data\n",
    "                dimensions = img.header.get_data_shape()\n",
    "                # Append the file name and its dimensions to the list\n",
    "                # Unpack the dimensions tuple directly into separate columns\n",
    "                product_of_dimensions = dimensions[0] * dimensions[1] * dimensions[2]\n",
    "                file_dimensions.append((filename, dimensions[0], dimensions[1], dimensions[2],product_of_dimensions))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "    # Create a DataFrame from the list of dimensions\n",
    "    df = pd.DataFrame(file_dimensions, columns=['File Name', 'Dimension 0', 'Dimension 1', 'Dimension 2', 'Total Voxels'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "directory = r\"C:\\Users\\acer\\Desktop\\Data_Prep_0\\imagesTr\"\n",
    "df = list_nii_dimensions(directory)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_histogram(df, column_name):\n",
    "    # Check if the column exists in the DataFrame\n",
    "    if column_name in df.columns:\n",
    "        # Plot histogram\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        #Change color to black and remove histtype for normal histogram\n",
    "        n,x,_ = plt.hist(df[column_name], bins=100,histtype=u'step', edgecolor='white')\n",
    "\n",
    "        #These 2 lines are for the orange line (graph from mid point of the bin of histogram)\n",
    "        bin_centers = 0.5*(x[1:]+x[:-1])\n",
    "        plt.plot(bin_centers, n, color='orange')\n",
    "\n",
    "        plt.title(f'Histogram of {column_name}')\n",
    "        plt.xlabel(column_name)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"The column '{column_name}' does not exist in the DataFrame.\")\n",
    "\n",
    "# Example usage\n",
    "# Assume 'df' is a DataFrame that includes a column named 'Dimension 0'\n",
    "\n",
    "plot_histogram(df, 'Dimension 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, 'Dimension 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, 'Dimension 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, 'Total Voxels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This funtion read both .nii and .nrrd as numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import nrrd\n",
    "import numpy as np\n",
    "\n",
    "def file_to_ndarray(filepath):\n",
    "    # Check the file extension\n",
    "    _, file_extension = os.path.splitext(filepath)\n",
    "    \n",
    "    try:\n",
    "        if file_extension in ['.nii', '.nii.gz']:  # Handle gzipped or regular NIfTI files\n",
    "            # Load the NIfTI file\n",
    "            nii_img = nib.load(filepath)\n",
    "            # Convert to ndarray\n",
    "            data = nii_img.get_fdata()\n",
    "            #print(f\"Loaded NIfTI file: {filepath}\")\n",
    "        elif file_extension == '.nrrd':\n",
    "            # Load the NRRD file\n",
    "            data, header = nrrd.read(filepath)\n",
    "            #print(f\"Loaded NRRD file: {filepath}\")\n",
    "        else:\n",
    "            print(\"Unsupported file format.\")\n",
    "            return None\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "# Replace 'filepath_to_nii_or_nrrd' with your actual file path\n",
    "\n",
    "nii_file_path = r\"C:\\Users\\acer\\Desktop\\Data_Prep_1\\imagesTr\\6659_2023_10_31_L.nii\"\n",
    "\n",
    "nii_ndarray = file_to_ndarray(nii_file_path)\n",
    "dim = nii_ndarray.shape\n",
    "print(f\"Dimension : {dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_histogram(ndarray):\n",
    "    # Flatten the ndarray to ensure all data is in a single dimension\n",
    "    flat_array = ndarray.flatten()\n",
    "\n",
    "    # Define the bin edges from -2000 to 2000 with a bin size of 10\n",
    "    bins = np.arange(-4000, 4001, 10)  # 2001 to include the endpoint 2000 in the last bin\n",
    "\n",
    "    # Compute histogram\n",
    "    histogram_values, bin_edges = np.histogram(flat_array, bins=bins)\n",
    "\n",
    "    # Convert histogram values to list\n",
    "    histogram_list = histogram_values.tolist()\n",
    "\n",
    "    #print(\"Histogram values:\", histogram_list)\n",
    "    #print(\"Bin edges:\", bin_edges)\n",
    "\n",
    "    return histogram_list, bin_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def append_to_csv(file_path, file_name, list_to_append):\n",
    "    # Open the file in append mode\n",
    "\n",
    "    list_to_append = [file_name] + list_to_append\n",
    "\n",
    "    with open(file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write the list as the last row in the CSV\n",
    "        writer.writerow(list_to_append)\n",
    "        print(\"Successfully to the CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_csv_as_dataframe(filepath):\n",
    "    # Read the CSV file without headers\n",
    "    df = pd.read_csv(filepath, header=None)\n",
    "\n",
    "    # Use the first column as the header\n",
    "    headers = df.iloc[:, 0]  # Extract the first column as headers\n",
    "    df = df.iloc[:, 1:]      # Remove the first column from the df\n",
    "    df = df.T\n",
    "    df.columns = headers     # Set the extracted column as headers\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_columns_of_dataframe(df, x_coords):\n",
    "    # Check if the length of x_coords matches the number of rows in the DataFrame\n",
    "    if len(x_coords) != len(df):\n",
    "        raise ValueError(\"Length of x_coords must match the number of rows in the DataFrame\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Loop through each column in the DataFrame and plot\n",
    "    for column in df.columns:\n",
    "        plt.plot(x_coords, df[column], label=f'Column: {column}')\n",
    "\n",
    "    plt.title('Voxels intensity distribution')\n",
    "    plt.xlabel('Voxels intensity')\n",
    "    plt.ylabel('Voxels count')\n",
    "    #plt.legend()\n",
    "    #plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't run next cell unless necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory path where the .nii files are located\n",
    "directory_path = r\"C:\\Users\\acer\\Desktop\\Data_Prep_1\\imagesTr\"  # Replace with your actual directory path\n",
    "csv_path = r\"C:\\Users\\acer\\Desktop\\Project\\Code\\voxels_intensity_dist.csv\"\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.nii'):\n",
    "        # Full path to the file\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        # Now you can use file_path to open the file or process it\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "\n",
    "        # Read .nii file\n",
    "        data = file_to_ndarray(file_path)\n",
    "\n",
    "        # Compute histogram\n",
    "        histogram_values, bin_edges = compute_histogram(data)\n",
    "\n",
    "        # Write to csv\n",
    "        append_to_csv(csv_path, filename, histogram_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\acer\\Desktop\\Data_Prep_0\\imagesTr\\66700681_2023_11_16_R.nii\"\n",
    "data = file_to_ndarray(file_path)\n",
    "histogram_values, bin_edges = compute_histogram(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv\n",
    "csv_path = r\"C:\\Users\\acer\\Desktop\\Project\\Code\\voxels_intensity_dist.csv\"\n",
    "csv_df = read_csv_as_dataframe(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_first_non_zero_to_zero(column):\n",
    "    # Find the first non-zero index\n",
    "    first_non_zero_idx = column.ne(0).idxmax()\n",
    "    # Check if the first non-zero index actually has a non-zero value (handles all-zero columns)\n",
    "    if column[first_non_zero_idx] != 0:\n",
    "        column.at[first_non_zero_idx] = 0\n",
    "    return column\n",
    "\n",
    "# Apply the function to each column\n",
    "probably_remove_background_df = csv_df.apply(set_first_non_zero_to_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coords = bin_edges[1:]\n",
    "plot_columns_of_dataframe(probably_remove_background_df, x_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def rounded_up_avg_max_indices(df):\n",
    "    # Calculate the index of the max value in each column\n",
    "    max_indices = df.apply(lambda x: x.idxmax())\n",
    "\n",
    "    # Compute the average of these indices\n",
    "    average_index = max_indices.mean()\n",
    "\n",
    "    # Use math.ceil to round up the average index\n",
    "    rounded_up_average = math.ceil(average_index)\n",
    "\n",
    "    return rounded_up_average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_peaks(df, target_index):\n",
    "    for column in df.columns:\n",
    "        # Find the index of the maximum value in the column\n",
    "        current_peak_index = df[column].idxmax()\n",
    "        \n",
    "        # Calculate how much to shift to align the peak with the target index\n",
    "        shift_amount = target_index - current_peak_index\n",
    "        \n",
    "        # Shift the column\n",
    "        df[column] = df[column].shift(shift_amount)\n",
    "        df = df.fillna(0)\n",
    "    \n",
    "    # Return the modified DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = rounded_up_avg_max_indices(probably_remove_background_df)\n",
    "aligned_peaks_df = align_peaks(probably_remove_background_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coords = bin_edges[1:]\n",
    "plot_columns_of_dataframe(aligned_peaks_df, x_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coords = bin_edges[1:]\n",
    "plot_columns_of_dataframe(csv_df, x_coords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
