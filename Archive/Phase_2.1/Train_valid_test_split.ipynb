{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "df = pd.read_excel(r\"C:\\Users\\acer\\Desktop\\Data_0\\Classification_1.xlsx\")\n",
    "\n",
    "# Fix seed for reproducibility\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Randomly shuffle the dataframe\n",
    "df = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "\n",
    "# Calculate split sizes\n",
    "total = len(df)\n",
    "train_split = int(0.7 * total)\n",
    "val_split = int(0.15 * total)\n",
    "\n",
    "# Split the dataframe\n",
    "train_df = df[:train_split]\n",
    "val_df = df[train_split:train_split+val_split]\n",
    "test_df = df[train_split+val_split:]\n",
    "\n",
    "# Create train, validation, and test folders and save the corresponding classification.xlsx files\n",
    "dict_df = {'train':train_df, 'validation':val_df, 'test':test_df}\n",
    "data_path = r\"C:\\Users\\acer\\Desktop\\Data_2D3layers\"\n",
    "for folder in ['train', 'validation', 'test']:\n",
    "    folder_path = os.path.join(data_path, folder)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    file_name = f'{folder}_classification.xlsx'\n",
    "    excel_path = os.path.join(folder_path, file_name)\n",
    "    dict_df[folder].to_excel(excel_path, index=False)\n",
    "\n",
    "# Get folder lists for each split\n",
    "train_folders = train_df['ID'].tolist()\n",
    "val_folders = val_df['ID'].tolist()\n",
    "test_folders = test_df['ID'].tolist()\n",
    "\n",
    "# Function to move folders\n",
    "def move_folders(folder_list, source_path, destination_path):\n",
    "    for folder in folder_list:\n",
    "        for xyz in ['x', 'y', 'z']:\n",
    "            folder_xyz = f\"{folder}_{xyz}\"\n",
    "            source = os.path.join(source_path, folder_xyz)\n",
    "            dest = os.path.join(destination_path, folder_xyz)\n",
    "            shutil.copytree(source, dest, dirs_exist_ok=True)\n",
    "\n",
    "# Move folders to their respective destinations\n",
    "source = r\"C:\\Users\\acer\\Desktop\\Data_0\\Nii_toJPG_3layers\"\n",
    "destination_train = r\"C:\\Users\\acer\\Desktop\\Data_2D3layers\\train\"\n",
    "destination_validation = r\"C:\\Users\\acer\\Desktop\\Data_2D3layers\\validation\"\n",
    "destination_test = r\"C:\\Users\\acer\\Desktop\\Data_2D3layers\\test\"\n",
    "move_folders(train_folders,source, destination_train)\n",
    "move_folders(val_folders,source, destination_validation)\n",
    "move_folders(test_folders,source, destination_test)\n",
    "\n",
    "print(\"Folders have been moved and Excel files have been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 364 existing files from CSV\n",
      "Input folder: /tmjoa_3d/data/5_adjustedBG\n",
      "ID column: 'ID', Class column: 'c_erosion'\n",
      "Class distribution:\n",
      "c_erosion\n",
      "1    201\n",
      "0    163\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Copying train files...\n",
      "  Copied: 254 files\n",
      "\n",
      "Copying validation files...\n",
      "  Copied: 73 files\n",
      "\n",
      "Copying test files...\n",
      "  Copied: 37 files\n",
      "\n",
      "==================================================\n",
      "SPLIT SUMMARY\n",
      "==================================================\n",
      "Total files: 364\n",
      "Train: 254 (69.8%)\n",
      "Val:   73 (20.1%)\n",
      "Test:  37 (10.2%)\n",
      "\n",
      "Class distribution by split:\n",
      "\n",
      "Train:\n",
      "  1: 140 (55.1%)\n",
      "  0: 114 (44.9%)\n",
      "\n",
      "Val:\n",
      "  1: 40 (54.8%)\n",
      "  0: 33 (45.2%)\n",
      "\n",
      "Test:\n",
      "  1: 21 (56.8%)\n",
      "  0: 16 (43.2%)\n",
      "\n",
      "Split CSV files saved in /tmjoa_3d/data/training_dataset\n",
      "Files organized in: /tmjoa_3d/data/training_dataset\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def create_train_val_test_split(csv_path, input_folder, output_dir, id_column='ID', class_column='Class', \n",
    "                                train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, stratify_by_class=True, random_state=42):\n",
    "    \"\"\"\n",
    "    Split dataset into train/validation/test sets and copy files accordingly.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    csv_path : str\n",
    "        Path to CSV file with ID and class columns\n",
    "    input_folder : str\n",
    "        Path to folder containing the .nii.gz files\n",
    "    output_dir : str\n",
    "        Base directory where train/val/test folders will be created\n",
    "    id_column : str\n",
    "        Name of the column containing file names (default: 'ID')\n",
    "    class_column : str\n",
    "        Name of the column containing class labels (default: 'Class')\n",
    "    train_ratio : float\n",
    "        Proportion for training set (default: 0.7)\n",
    "    val_ratio : float\n",
    "        Proportion for validation set (default: 0.15)\n",
    "    test_ratio : float\n",
    "        Proportion for test set (default: 0.15)\n",
    "    stratify_by_class : bool\n",
    "        Whether to maintain class distribution across splits (default: True)\n",
    "    random_state : int\n",
    "        Random seed for reproducibility (default: 42)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate ratios\n",
    "    if abs(train_ratio + val_ratio + test_ratio - 1.0) > 1e-6:\n",
    "        raise ValueError(\"Train, validation, and test ratios must sum to 1.0\")\n",
    "    \n",
    "    # Read CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Validate required columns\n",
    "    if id_column not in df.columns or class_column not in df.columns:\n",
    "        raise ValueError(f\"CSV must contain '{id_column}' and '{class_column}' columns\")\n",
    "    \n",
    "    # Create full file paths by combining input_folder with filenames\n",
    "    df['full_path'] = df[id_column].apply(lambda x: os.path.join(input_folder, f\"{x}_adjustedBG.nii.gz\"))\n",
    "    \n",
    "    # Check which files exist\n",
    "    existing_files = df['full_path'].apply(os.path.exists)\n",
    "    missing_files = df[~existing_files]\n",
    "    \n",
    "    if len(missing_files) > 0:\n",
    "        print(f\"Warning: {len(missing_files)} files not found in {input_folder}\")\n",
    "        print(\"Missing files:\")\n",
    "        for _, row in missing_files.head(5).iterrows():\n",
    "            print(f\"  - {row[id_column]}\")\n",
    "        if len(missing_files) > 5:\n",
    "            print(f\"  ... and {len(missing_files) - 5} more\")\n",
    "        print()\n",
    "        \n",
    "        # Remove missing files from dataframe\n",
    "        df = df[existing_files].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Loaded {len(df)} existing files from CSV\")\n",
    "    print(f\"Input folder: {input_folder}\")\n",
    "    print(f\"ID column: '{id_column}', Class column: '{class_column}'\")\n",
    "    print(f\"Class distribution:\")\n",
    "    print(df[class_column].value_counts())\n",
    "    print()\n",
    "    \n",
    "    # Create output directories\n",
    "    output_path = Path(output_dir)\n",
    "    train_dir = output_path / 'train'\n",
    "    val_dir = output_path / 'val'\n",
    "    test_dir = output_path / 'test'\n",
    "    \n",
    "    for dir_path in [train_dir, val_dir, test_dir]:\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        # Create class subdirectories\n",
    "        for class_name in df[class_column].unique():\n",
    "            (dir_path / str(class_name)).mkdir(exist_ok=True)\n",
    "    \n",
    "    # Prepare stratification\n",
    "    stratify = df[class_column] if stratify_by_class else None\n",
    "    \n",
    "    # First split: separate train from (val + test)\n",
    "    temp_val_test_ratio = val_ratio + test_ratio\n",
    "    train_df, val_test_df = train_test_split(\n",
    "        df, \n",
    "        test_size=temp_val_test_ratio,\n",
    "        stratify=stratify,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Second split: separate val from test\n",
    "    # Adjust the test_size for the second split\n",
    "    test_ratio_adjusted = test_ratio / temp_val_test_ratio\n",
    "    stratify_val_test = val_test_df[class_column] if stratify_by_class else None\n",
    "    \n",
    "    val_df, test_df = train_test_split(\n",
    "        val_test_df,\n",
    "        test_size=test_ratio_adjusted,\n",
    "        stratify=stratify_val_test,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Copy files function\n",
    "    def copy_files(df_subset, target_dir, split_name):\n",
    "        print(f\"Copying {split_name} files...\")\n",
    "        copied_count = 0\n",
    "        missing_count = 0\n",
    "        \n",
    "        for idx, row in df_subset.iterrows():\n",
    "            source_path = row['full_path']\n",
    "            class_name = row[class_column]\n",
    "            filename = f\"{row[id_column]}_adjustedBG.nii.gz\"  # Use original filename from CSV\n",
    "            \n",
    "            # Check if source file exists (should exist since we filtered above)\n",
    "            if not os.path.exists(source_path):\n",
    "                print(f\"Warning: File not found: {source_path}\")\n",
    "                missing_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Create destination path\n",
    "            dest_path = target_dir / str(class_name) / filename\n",
    "            \n",
    "            # Copy file\n",
    "            try:\n",
    "                shutil.copy2(source_path, dest_path)\n",
    "                copied_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {source_path}: {e}\")\n",
    "                missing_count += 1\n",
    "        \n",
    "        print(f\"  Copied: {copied_count} files\")\n",
    "        if missing_count > 0:\n",
    "            print(f\"  Missing/Failed: {missing_count} files\")\n",
    "        print()\n",
    "        \n",
    "        return copied_count, missing_count\n",
    "    \n",
    "    # Copy files to respective directories\n",
    "    results = {}\n",
    "    results['train'] = copy_files(train_df, train_dir, 'train')\n",
    "    results['val'] = copy_files(val_df, val_dir, 'validation')\n",
    "    results['test'] = copy_files(test_df, test_dir, 'test')\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"=\"*50)\n",
    "    print(\"SPLIT SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total files: {len(df)}\")\n",
    "    print(f\"Train: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"Val:   {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"Test:  {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "    print()\n",
    "    \n",
    "    # Print class distribution for each split\n",
    "    if stratify_by_class:\n",
    "        print(\"Class distribution by split:\")\n",
    "        for split_name, df_subset in [('Train', train_df), ('Val', val_df), ('Test', test_df)]:\n",
    "            print(f\"\\n{split_name}:\")\n",
    "            class_counts = df_subset[class_column].value_counts()\n",
    "            for class_name, count in class_counts.items():\n",
    "                percentage = count / len(df_subset) * 100\n",
    "                print(f\"  {class_name}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Save split information (only include relevant columns)\n",
    "    cols_to_save = [id_column, class_column]\n",
    "    train_df[cols_to_save].to_csv(output_path / 'train_split.csv', index=False)\n",
    "    val_df[cols_to_save].to_csv(output_path / 'val_split.csv', index=False)\n",
    "    test_df[cols_to_save].to_csv(output_path / 'test_split.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nSplit CSV files saved in {output_path}\")\n",
    "    print(f\"Files organized in: {output_path}\")\n",
    "    \n",
    "    return {\n",
    "        'train_df': train_df,\n",
    "        'val_df': val_df,\n",
    "        'test_df': test_df,\n",
    "        'results': results\n",
    "    }\n",
    "\n",
    "csv_file = r\"/tmjoa_3d/data/Classification_1.csv\"\n",
    "input_folder = r\"/tmjoa_3d/data/5_adjustedBG\"\n",
    "output_directory = r\"/tmjoa_3d/data/training_dataset\"\n",
    "\n",
    "results = create_train_val_test_split(\n",
    "    csv_path=csv_file,\n",
    "    input_folder=input_folder,\n",
    "    output_dir=output_directory,\n",
    "    id_column='ID',  # Your column name for filenames\n",
    "    class_column='c_erosion',  # Your column name for classes\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.1,\n",
    "    stratify_by_class=True,\n",
    "    random_state=42\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
