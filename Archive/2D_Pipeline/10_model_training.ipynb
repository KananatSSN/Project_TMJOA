{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "print(tf.__version__, np.__version__)\n",
    "\n",
    "# Expected output 2.9.0, 1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect GPU and limit memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus != []:\n",
    "    print(gpus)\n",
    "    for gpu in gpus: \n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"No GPU on this machine\")\n",
    "\n",
    "# Expected output [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
    "if USE_GPU == False:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found and successfully configured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(dataset_dir, batch_size=8):\n",
    "\n",
    "    print(f\"Loading training data from {train_data_dir}...\")\n",
    "\n",
    "    train_data_dir = os.path.join(dataset_dir, \"train\")\n",
    "\n",
    "    train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "        train_data_dir,\n",
    "        image_size=(224, 224),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    val_data_dir = os.path.join(dataset_dir, \"val\")\n",
    "\n",
    "    val_data = tf.keras.utils.image_dataset_from_directory(\n",
    "        val_data_dir,\n",
    "        image_size=(224, 224),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    train = train_data\n",
    "    val = val_data\n",
    "\n",
    "    return train, val\n",
    "\n",
    "def load_test_data(test_data_dir, batch_size=8):\n",
    "\n",
    "    print(f\"Loading testing data from {test_data_dir}...\")\n",
    "\n",
    "    test_data = tf.keras.utils.image_dataset_from_directory(\n",
    "        test_data_dir,\n",
    "        image_size=(224, 224),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = ['DesnseNet201']\n",
    "INPUT_SHAPE = (224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_model = ['DenseNet201', 'EfficientNetB7', 'EfficientNetV2L','InceptionResNetV2', 'InceptionV3', 'MobileNetV3Large', 'NASNetLarge', 'ResNet152', 'ResNet152V2', 'VGG19', 'Xception']\n",
    "\n",
    "def get_base_model(model_name, input_shape):\n",
    "    model_dict = {\n",
    "        'DenseNet201': tf.keras.applications.DenseNet201,\n",
    "        'EfficientNetB7': tf.keras.applications.EfficientNetB7,\n",
    "        'EfficientNetV2L': tf.keras.applications.EfficientNetV2L,\n",
    "        'InceptionResNetV2': tf.keras.applications.InceptionResNetV2,\n",
    "        'InceptionV3': tf.keras.applications.InceptionV3,\n",
    "        'MobileNetV3Large': tf.keras.applications.MobileNetV3Large,\n",
    "        'NASNetLarge': tf.keras.applications.NASNetLarge,\n",
    "        'ResNet152': tf.keras.applications.ResNet152,\n",
    "        'ResNet152V2': tf.keras.applications.ResNet152V2,\n",
    "        'VGG19': tf.keras.applications.VGG19,\n",
    "        'Xception': tf.keras.applications.Xception,\n",
    "    }\n",
    "    \n",
    "    if model_name not in model_dict:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "    \n",
    "    return model_dict[model_name](input_shape=input_shape, include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(base_model, input_shape):\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    print(\"Built model\")\n",
    "    pd.set_option('max_colwidth', None)\n",
    "    layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
    "    pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Usage example\n",
    "\n",
    "# input_shape = (224, 224, 3)\n",
    "# base_model = get_base_model(model_name, input_shape)\n",
    "# model = build_model(base_model, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(model_name, results_dir, models_dir, lr_suffix=\"001\"):\n",
    "    log_file = os.path.join(results_dir, f\"{model_name}_bo20_lr{lr_suffix}.csv\")\n",
    "    return [\n",
    "        CSVLogger(log_file),\n",
    "        ModelCheckpoint(\n",
    "            filepath=os.path.join(models_dir, f\"{model_name}_bo20_lr{lr_suffix}.h5\"),\n",
    "            save_weights_only=False,\n",
    "            save_best_only=True,\n",
    "            save_freq='epoch',\n",
    "            verbose=1\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, model_name, results_dir, lr_suffix=\"001\"):\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "    plt.title(f'{model_name} Loss (LR: 0.{lr_suffix})')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.savefig(os.path.join(results_dir, f\"{model_name}_loss_lr{lr_suffix}.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_name, test_data, models_dir):\n",
    "    model = tf.keras.models.load_model(os.path.join(models_dir, f\"{model_name}_bo20_lr0001.h5\"))\n",
    "    pre = Precision()\n",
    "    re = Recall()\n",
    "    acc = BinaryAccuracy()\n",
    "\n",
    "    for batch in test_data.as_numpy_iterator():\n",
    "        X, y = batch\n",
    "        yhat = model.predict(X)\n",
    "        pre.update_state(y, yhat)\n",
    "        re.update_state(y, yhat)\n",
    "        acc.update_state(y, yhat)\n",
    "\n",
    "    f1_score = 2 * (pre.result() * re.result()) / (pre.result() + re.result())\n",
    "    print(f\"{model_name} Test Results:\")\n",
    "    print(f\"Precision: {pre.result():.4f}\")\n",
    "    print(f\"Recall: {re.result():.4f}\")\n",
    "    print(f\"Accuracy: {acc.result():.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(model_names, train_data_dir, test_data_dir, results_base_dir, models_base_dir, epochs=20, batch_size=32):\n",
    "    \n",
    "    train, val = load_training_data(train_data_dir, train_data_ratio=0.8, batch_size=batch_size)\n",
    "\n",
    "    for model_name in model_names:\n",
    "        print(f\"Training {model_name}...\")\n",
    "\n",
    "        # Set up model-specific directories\n",
    "        results_dir = os.path.join(results_base_dir, model_name)\n",
    "        models_dir = os.path.join(models_base_dir, model_name)\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "        # Build model\n",
    "        input_shape = (224, 224, 3)\n",
    "        base_model = get_base_model(model_name, input_shape)\n",
    "        model = build_model(base_model, input_shape)\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=1e-2),\n",
    "            metrics=[keras.metrics.BinaryAccuracy()]\n",
    "        )\n",
    "\n",
    "        # Print model summary\n",
    "        model.summary()\n",
    "        \n",
    "        # Set up callbacks\n",
    "        callbacks = get_callbacks(model_name, results_dir, models_dir)\n",
    "\n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            train,\n",
    "            validation_data=val,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        # Plot training history\n",
    "        plot_training_history(history, model_name, results_dir)\n",
    "\n",
    "        # Reduce learning rate and continue training\n",
    "        model = load_model(os.path.join(models_dir, f\"{model_name}_bo{epochs}_lr001.h5\"))\n",
    "        model.compile(\n",
    "            loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            metrics=[keras.metrics.BinaryAccuracy()]\n",
    "        )\n",
    "\n",
    "        callbacks = get_callbacks(model_name, results_dir, models_dir, lr_suffix=\"0001\")\n",
    "        history = model.fit(\n",
    "            train,\n",
    "            validation_data=val,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        plot_training_history(history, model_name, results_dir, lr_suffix=\"0001\")\n",
    "\n",
    "        # Test model\n",
    "\n",
    "        test_data = load_test_data(test_data_dir, batch_size=1)\n",
    "        test_model(model_name, test_data, models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_train = ['EfficientNetB7', 'EfficientNetV2L','InceptionResNetV2', 'InceptionV3', 'MobileNetV3Large', 'ResNet152', 'ResNet152V2', 'VGG19', 'Xception']\n",
    "# trained = ['DenseNet201', ]\n",
    "# error : NASNetLarge\n",
    "train_data_dir = r\"D:\\Kananat\\TF_TMJOA_jpg_x_10px\"\n",
    "test_data_dir = r\"D:\\Kananat\\TF_TMJOA_jpg_x_10px_test\"\n",
    "\n",
    "results_base_dir = r\"D:\\Kananat\\_result\\logs\"\n",
    "models_base_dir = r\"D:\\Kananat\\_result\\models\"\n",
    "\n",
    "train_models(model_to_train, train_data_dir, test_data_dir, results_base_dir, models_base_dir, epochs=20, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2dmodelGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
