{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def predict_single_image(model, image_path, image_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image using a YOLOv8-cls model.\n",
    "    \n",
    "    Args:\n",
    "        model: A loaded YOLOv8-cls model\n",
    "        image_path: String path to the image file\n",
    "        image_size: Tuple of (width, height) for input image size, default (224, 224)\n",
    "    \"\"\"\n",
    "    # Open and preprocess the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    \n",
    "    # Resize the image - note that PIL takes (width, height)\n",
    "    img = img.resize(image_size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Convert to numpy array and ensure correct dimensions\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Ensure the image has the right shape (height, width, channels)\n",
    "    # print(f\"Image shape before processing: {img_array.shape}\")\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    img_array = img_array.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Make prediction\n",
    "    results = model.predict(source=image_path, verbose=False)\n",
    "    \n",
    "    # Process results\n",
    "    # Get the probabilities from the results\n",
    "    probs = results[0].probs\n",
    "    predicted_class = int(probs.top1)\n",
    "    confidence = float(probs.top1conf)\n",
    "    \n",
    "    return {\n",
    "        'predicted_class': predicted_class,\n",
    "        'confidence': confidence,\n",
    "        'all_probabilities': probs.data.tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your model\n",
    "model = YOLO(r'C:\\Users\\kanan\\Desktop\\Project_TMJOA\\2D_Pipeline\\YOLO\\runs\\classify\\train\\weights\\best.pt')  # Replace with your model path\n",
    "\n",
    "# Path to your image\n",
    "image_path = r'D:\\Kananat\\TF_TMJOA_jpg_x_5px_test_batch_by_ID\\erosion_0\\51-3282 R\\51-3282 R_x_088.jpg'  # Replace with your image path\n",
    "\n",
    "# Get prediction\n",
    "result = predict_single_image(model, image_path)\n",
    "\n",
    "# Print results in a readable format\n",
    "print(f\"Predicted class: {result['predicted_class']}\")\n",
    "print(f\"Confidence: {result['confidence']:.2%}\")\n",
    "print(f\"all_probabilities: {result['all_probabilities']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_folder_images(model, folder_path):\n",
    "    \"\"\"\n",
    "    Predict classes for all images in a given folder using a YOLOv8-cls model.\n",
    "    \n",
    "    Args:\n",
    "        model: A loaded YOLOv8-cls model\n",
    "        folder_path: String or Path object pointing to the folder containing images\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary where:\n",
    "            - keys are image filenames\n",
    "            - values are prediction dictionaries containing:\n",
    "                - predicted_class\n",
    "                - confidence\n",
    "                - all_probabilities\n",
    "    \"\"\"\n",
    "    # Convert folder_path to Path object for better path handling\n",
    "    folder_path = Path(folder_path)\n",
    "    \n",
    "    # Dictionary to store results for each image\n",
    "    predictions = {}\n",
    "    \n",
    "    # List of common image extensions we want to process\n",
    "    # We can easily add more extensions if needed\n",
    "    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')\n",
    "    \n",
    "    try:\n",
    "        # Iterate through all files in the folder\n",
    "        for file_path in folder_path.iterdir():\n",
    "            # Check if the file is an image by looking at its extension\n",
    "            if file_path.suffix.lower() in image_extensions:\n",
    "                try:\n",
    "                    # Get predictions for this image\n",
    "                    result = predict_single_image(model, str(file_path))\n",
    "                    \n",
    "                    # Store the result with the filename as key\n",
    "                    predictions[file_path.name] = result\n",
    "                    \n",
    "                    # Print progress (optional, but helpful for monitoring)\n",
    "                    # print(f\"Processed {file_path.name}: Class {result['predicted_class']} \"\n",
    "                          # f\"with confidence {result['confidence']:.2%}\")\n",
    "                          \n",
    "                except Exception as e:\n",
    "                    # If there's an error with one image, log it but continue processing others\n",
    "                    print(f\"Error processing {file_path.name}: {str(e)}\")\n",
    "                    predictions[file_path.name] = {\"error\": str(e)}\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle any errors that might occur when accessing the folder\n",
    "        raise Exception(f\"Error accessing folder {folder_path}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_063.jpg: Class 1 with confidence 52.30%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_064.jpg: Class 0 with confidence 52.53%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_065.jpg: Class 0 with confidence 62.12%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_066.jpg: Class 0 with confidence 84.38%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_067.jpg: Class 0 with confidence 94.96%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_068.jpg: Class 1 with confidence 58.82%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_069.jpg: Class 1 with confidence 91.92%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_070.jpg: Class 1 with confidence 98.85%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_071.jpg: Class 1 with confidence 98.70%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_072.jpg: Class 1 with confidence 92.48%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_073.jpg: Class 1 with confidence 99.42%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_074.jpg: Class 1 with confidence 99.98%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_075.jpg: Class 1 with confidence 99.99%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_076.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_077.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_078.jpg: Class 1 with confidence 99.99%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_079.jpg: Class 1 with confidence 99.99%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_080.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_081.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_082.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_083.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_084.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_085.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_086.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_087.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_088.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_089.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_090.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_091.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_092.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_093.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_094.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_095.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_096.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_097.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_098.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_099.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_100.jpg: Class 1 with confidence 99.97%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_101.jpg: Class 1 with confidence 99.99%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_102.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_103.jpg: Class 1 with confidence 99.97%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_104.jpg: Class 1 with confidence 99.91%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_105.jpg: Class 1 with confidence 73.54%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_106.jpg: Class 0 with confidence 94.85%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_107.jpg: Class 0 with confidence 85.85%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_108.jpg: Class 1 with confidence 69.67%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_109.jpg: Class 1 with confidence 90.58%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_110.jpg: Class 1 with confidence 87.03%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_111.jpg: Class 1 with confidence 91.91%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_112.jpg: Class 1 with confidence 92.29%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_113.jpg: Class 1 with confidence 97.85%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_114.jpg: Class 1 with confidence 88.37%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_115.jpg: Class 1 with confidence 56.58%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_116.jpg: Class 1 with confidence 99.26%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_117.jpg: Class 1 with confidence 99.98%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_118.jpg: Class 1 with confidence 99.95%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_119.jpg: Class 1 with confidence 99.94%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_120.jpg: Class 1 with confidence 99.99%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_121.jpg: Class 1 with confidence 99.99%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_122.jpg: Class 1 with confidence 99.98%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_123.jpg: Class 1 with confidence 99.88%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_124.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_125.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_126.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_127.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_128.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_129.jpg: Class 1 with confidence 99.99%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_130.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_131.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_132.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_133.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_134.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_135.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_136.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_137.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_138.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_139.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_140.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_141.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_142.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_143.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_144.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_145.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_146.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_147.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_148.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_149.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_150.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_151.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_152.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_153.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_154.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_155.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_156.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_157.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_158.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_159.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_160.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_161.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_162.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_163.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_164.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_165.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_166.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_167.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_168.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_169.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_170.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_171.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_172.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_173.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_174.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_175.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_176.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_177.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_178.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_179.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_180.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_181.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_182.jpg: Class 1 with confidence 100.00%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_183.jpg: Class 1 with confidence 99.99%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_184.jpg: Class 1 with confidence 99.98%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_185.jpg: Class 1 with confidence 99.98%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_186.jpg: Class 1 with confidence 99.97%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_187.jpg: Class 1 with confidence 99.96%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_188.jpg: Class 1 with confidence 99.96%\n",
      "Image shape before processing: (224, 224, 3)\n",
      "Processed 65-23331 R_x_189.jpg: Class 1 with confidence 99.92%\n",
      "\n",
      "Prediction Summary:\n",
      "--------------------------------------------------\n",
      "65-23331 R_x_063.jpg: Class 1 (Confidence: 52.30%)\n",
      "65-23331 R_x_064.jpg: Class 0 (Confidence: 52.53%)\n",
      "65-23331 R_x_065.jpg: Class 0 (Confidence: 62.12%)\n",
      "65-23331 R_x_066.jpg: Class 0 (Confidence: 84.38%)\n",
      "65-23331 R_x_067.jpg: Class 0 (Confidence: 94.96%)\n",
      "65-23331 R_x_068.jpg: Class 1 (Confidence: 58.82%)\n",
      "65-23331 R_x_069.jpg: Class 1 (Confidence: 91.92%)\n",
      "65-23331 R_x_070.jpg: Class 1 (Confidence: 98.85%)\n",
      "65-23331 R_x_071.jpg: Class 1 (Confidence: 98.70%)\n",
      "65-23331 R_x_072.jpg: Class 1 (Confidence: 92.48%)\n",
      "65-23331 R_x_073.jpg: Class 1 (Confidence: 99.42%)\n",
      "65-23331 R_x_074.jpg: Class 1 (Confidence: 99.98%)\n",
      "65-23331 R_x_075.jpg: Class 1 (Confidence: 99.99%)\n",
      "65-23331 R_x_076.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_077.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_078.jpg: Class 1 (Confidence: 99.99%)\n",
      "65-23331 R_x_079.jpg: Class 1 (Confidence: 99.99%)\n",
      "65-23331 R_x_080.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_081.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_082.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_083.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_084.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_085.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_086.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_087.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_088.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_089.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_090.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_091.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_092.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_093.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_094.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_095.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_096.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_097.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_098.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_099.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_100.jpg: Class 1 (Confidence: 99.97%)\n",
      "65-23331 R_x_101.jpg: Class 1 (Confidence: 99.99%)\n",
      "65-23331 R_x_102.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_103.jpg: Class 1 (Confidence: 99.97%)\n",
      "65-23331 R_x_104.jpg: Class 1 (Confidence: 99.91%)\n",
      "65-23331 R_x_105.jpg: Class 1 (Confidence: 73.54%)\n",
      "65-23331 R_x_106.jpg: Class 0 (Confidence: 94.85%)\n",
      "65-23331 R_x_107.jpg: Class 0 (Confidence: 85.85%)\n",
      "65-23331 R_x_108.jpg: Class 1 (Confidence: 69.67%)\n",
      "65-23331 R_x_109.jpg: Class 1 (Confidence: 90.58%)\n",
      "65-23331 R_x_110.jpg: Class 1 (Confidence: 87.03%)\n",
      "65-23331 R_x_111.jpg: Class 1 (Confidence: 91.91%)\n",
      "65-23331 R_x_112.jpg: Class 1 (Confidence: 92.29%)\n",
      "65-23331 R_x_113.jpg: Class 1 (Confidence: 97.85%)\n",
      "65-23331 R_x_114.jpg: Class 1 (Confidence: 88.37%)\n",
      "65-23331 R_x_115.jpg: Class 1 (Confidence: 56.58%)\n",
      "65-23331 R_x_116.jpg: Class 1 (Confidence: 99.26%)\n",
      "65-23331 R_x_117.jpg: Class 1 (Confidence: 99.98%)\n",
      "65-23331 R_x_118.jpg: Class 1 (Confidence: 99.95%)\n",
      "65-23331 R_x_119.jpg: Class 1 (Confidence: 99.94%)\n",
      "65-23331 R_x_120.jpg: Class 1 (Confidence: 99.99%)\n",
      "65-23331 R_x_121.jpg: Class 1 (Confidence: 99.99%)\n",
      "65-23331 R_x_122.jpg: Class 1 (Confidence: 99.98%)\n",
      "65-23331 R_x_123.jpg: Class 1 (Confidence: 99.88%)\n",
      "65-23331 R_x_124.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_125.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_126.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_127.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_128.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_129.jpg: Class 1 (Confidence: 99.99%)\n",
      "65-23331 R_x_130.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_131.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_132.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_133.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_134.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_135.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_136.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_137.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_138.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_139.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_140.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_141.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_142.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_143.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_144.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_145.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_146.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_147.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_148.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_149.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_150.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_151.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_152.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_153.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_154.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_155.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_156.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_157.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_158.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_159.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_160.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_161.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_162.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_163.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_164.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_165.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_166.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_167.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_168.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_169.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_170.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_171.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_172.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_173.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_174.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_175.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_176.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_177.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_178.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_179.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_180.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_181.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_182.jpg: Class 1 (Confidence: 100.00%)\n",
      "65-23331 R_x_183.jpg: Class 1 (Confidence: 99.99%)\n",
      "65-23331 R_x_184.jpg: Class 1 (Confidence: 99.98%)\n",
      "65-23331 R_x_185.jpg: Class 1 (Confidence: 99.98%)\n",
      "65-23331 R_x_186.jpg: Class 1 (Confidence: 99.97%)\n",
      "65-23331 R_x_187.jpg: Class 1 (Confidence: 99.96%)\n",
      "65-23331 R_x_188.jpg: Class 1 (Confidence: 99.96%)\n",
      "65-23331 R_x_189.jpg: Class 1 (Confidence: 99.92%)\n"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "images_folder = r'D:\\Kananat\\TF_TMJOA_jpg_x_5px_test_batch_by_ID\\erosion_1\\65-23331 R'  # Replace with your folder path\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(r'C:\\Users\\kanan\\Desktop\\Project_TMJOA\\2D_Pipeline\\YOLO\\runs\\classify\\train\\weights\\best.pt')  # Replace with your model path\n",
    "\n",
    "# Process all images\n",
    "results = predict_folder_images(model, images_folder)\n",
    "\n",
    "# Print a summary of the results\n",
    "print(\"\\nPrediction Summary:\")\n",
    "print(\"-\" * 50)\n",
    "for image_name, prediction in results.items():\n",
    "    if \"error\" in prediction:\n",
    "        print(f\"{image_name}: Error - {prediction['error']}\")\n",
    "    else:\n",
    "        print(f\"{image_name}: Class {prediction['predicted_class']} \"\n",
    "                f\"(Confidence: {prediction['confidence']:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_final_prediction(predictions, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Make a final binary classification (0 or 1) based on multiple predictions.\n",
    "    \n",
    "    This function implements a majority voting system, where the final class\n",
    "    is determined by which class (0 or 1) appears more frequently in the\n",
    "    predictions that meet our confidence threshold.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Dictionary where keys are image names and values are prediction\n",
    "                    dictionaries containing 'predicted_class' and 'confidence'\n",
    "        confidence_threshold: Minimum confidence level to consider a prediction\n",
    "                            (default 0.0 means consider all predictions)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "        - final_class: The majority class (0 or 1)\n",
    "        - confidence_score: Proportion of predictions supporting the majority class\n",
    "        - detailed_stats: Additional statistics about the predictions\n",
    "    \"\"\"\n",
    "    # Initialize counters for each class\n",
    "    class_counts = {0: 0, 1: 0}\n",
    "    \n",
    "    # Count valid predictions (those without errors and above threshold)\n",
    "    total_valid_predictions = 0\n",
    "    \n",
    "    # Keep track of confidence scores for detailed analysis\n",
    "    confidence_scores = {0: [], 1: []}\n",
    "    \n",
    "    # Process each prediction\n",
    "    for image_name, pred in predictions.items():\n",
    "        # Skip any predictions that had errors\n",
    "        if \"error\" in pred:\n",
    "            continue\n",
    "            \n",
    "        # Get the prediction and confidence\n",
    "        pred_class = pred['predicted_class']\n",
    "        confidence = pred['confidence']\n",
    "        \n",
    "        # Only count predictions above our confidence threshold\n",
    "        if confidence >= confidence_threshold:\n",
    "            class_counts[pred_class] += 1\n",
    "            confidence_scores[pred_class].append(confidence)\n",
    "            total_valid_predictions += 1\n",
    "    \n",
    "    # If we have no valid predictions, we can't make a decision\n",
    "    if total_valid_predictions == 0:\n",
    "        return {\n",
    "            'final_class': None,\n",
    "            'confidence_score': 0.0,\n",
    "            'detailed_stats': {\n",
    "                'error': 'No valid predictions found',\n",
    "                'class_counts': class_counts,\n",
    "                'total_predictions': total_valid_predictions\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Determine which class has the majority\n",
    "    final_class = 0 if class_counts[0] >= class_counts[1] else 1\n",
    "    \n",
    "    # Calculate our confidence in this decision\n",
    "    # This is the proportion of predictions that agree with our final decision\n",
    "    confidence_score = class_counts[final_class] / total_valid_predictions\n",
    "    \n",
    "    # Calculate average confidence for each class\n",
    "    avg_confidence = {\n",
    "        0: sum(confidence_scores[0]) / len(confidence_scores[0]) if confidence_scores[0] else 0,\n",
    "        1: sum(confidence_scores[1]) / len(confidence_scores[1]) if confidence_scores[1] else 0\n",
    "    }\n",
    "    \n",
    "    # Prepare detailed statistics\n",
    "    detailed_stats = {\n",
    "        'class_counts': class_counts,\n",
    "        'total_predictions': total_valid_predictions,\n",
    "        'predictions_above_threshold': total_valid_predictions,\n",
    "        'average_confidence_per_class': avg_confidence,\n",
    "        'majority_percentage': confidence_score * 100\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'final_class': final_class,\n",
    "        'confidence_score': confidence_score,\n",
    "        'detailed_stats': detailed_stats\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Classification Results:\n",
      "--------------------------------------------------\n",
      "Final Class: 1\n",
      "Confidence Score: 95.28%\n",
      "\n",
      "Detailed Statistics:\n",
      "Class 0 count: 6\n",
      "Class 1 count: 121\n",
      "Total valid predictions: 127\n",
      "Average confidence for class 0: 79.12%\n",
      "Average confidence for class 1: 97.84%\n",
      "Majority class percentage: 95.3%\n"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "images_folder = r'D:\\Kananat\\TF_TMJOA_jpg_x_5px_test_batch_by_ID\\erosion_1\\65-23331 R'  # Replace with your folder path\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(r'C:\\Users\\kanan\\Desktop\\Project_TMJOA\\2D_Pipeline\\YOLO\\runs\\classify\\train\\weights\\best.pt')  # Replace with your model path\n",
    "\n",
    "predictions = predict_folder_images(model, images_folder)\n",
    "\n",
    "# Make final prediction with a confidence threshold\n",
    "final_result = make_final_prediction(predictions, confidence_threshold=0.5)\n",
    "\n",
    "# Print the results in a readable format\n",
    "print(\"\\nFinal Classification Results:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Final Class: {final_result['final_class']}\")\n",
    "print(f\"Confidence Score: {final_result['confidence_score']:.2%}\")\n",
    "print(\"\\nDetailed Statistics:\")\n",
    "stats = final_result['detailed_stats']\n",
    "print(f\"Class 0 count: {stats['class_counts'][0]}\")\n",
    "print(f\"Class 1 count: {stats['class_counts'][1]}\")\n",
    "print(f\"Total valid predictions: {stats['total_predictions']}\")\n",
    "print(f\"Average confidence for class 0: {stats['average_confidence_per_class'][0]:.2%}\")\n",
    "print(f\"Average confidence for class 1: {stats['average_confidence_per_class'][1]:.2%}\")\n",
    "print(f\"Majority class percentage: {stats['majority_percentage']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def analyze_multiple_folders(base_folder_path, model, confidence_threshold=0.0):\n",
    "    \"\"\"\n",
    "    Analyze all folders within a base folder, making predictions for each folder\n",
    "    and compiling the results into a comprehensive report.\n",
    "    \n",
    "    Args:\n",
    "        base_folder_path: Path to the folder containing multiple subfolders with images\n",
    "        model: Loaded YOLOv8-cls model\n",
    "        confidence_threshold: Minimum confidence level for considering predictions\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing results for each folder and a summary DataFrame\n",
    "    \"\"\"\n",
    "    # Convert to Path object for better path handling\n",
    "    base_path = Path(base_folder_path)\n",
    "    \n",
    "    # Dictionary to store results for each folder\n",
    "    folder_results = {}\n",
    "    \n",
    "    # List to store results for DataFrame creation\n",
    "    results_for_df = []\n",
    "    \n",
    "    # Process each subfolder in the base folder\n",
    "    for folder_path in base_path.iterdir():\n",
    "        # Skip if it's not a directory\n",
    "        if not folder_path.is_dir():\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing folder: {folder_path.name}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Get predictions for all images in this folder\n",
    "            folder_predictions = predict_folder_images(model, folder_path)\n",
    "            \n",
    "            # Make final prediction for this folder\n",
    "            final_result = make_final_prediction(\n",
    "                folder_predictions, \n",
    "                confidence_threshold=confidence_threshold\n",
    "            )\n",
    "            \n",
    "            # Store detailed results\n",
    "            folder_results[folder_path.name] = {\n",
    "                'predictions': folder_predictions,\n",
    "                'final_result': final_result\n",
    "            }\n",
    "            \n",
    "            # Add to our DataFrame results\n",
    "            results_for_df.append({\n",
    "                'Folder': folder_path.name,\n",
    "                'Final Class': final_result['final_class'],\n",
    "                'Confidence Score': final_result['confidence_score'],\n",
    "                'Total Images': final_result['detailed_stats']['total_predictions'],\n",
    "                'Class 0 Count': final_result['detailed_stats']['class_counts'][0],\n",
    "                'Class 1 Count': final_result['detailed_stats']['class_counts'][1],\n",
    "                'Average Conf Class 0': final_result['detailed_stats']['average_confidence_per_class'][0],\n",
    "                'Average Conf Class 1': final_result['detailed_stats']['average_confidence_per_class'][1]\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing folder {folder_path.name}: {str(e)}\")\n",
    "            folder_results[folder_path.name] = {'error': str(e)}\n",
    "    \n",
    "    # Create DataFrame for easy analysis\n",
    "    results_df = pd.DataFrame(results_for_df)\n",
    "    \n",
    "    # Generate summary report\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    report_path = base_path / f\"analysis_report_{timestamp}.csv\"\n",
    "    results_df.to_csv(report_path, index=False)\n",
    "    \n",
    "    return {\n",
    "        'folder_results': folder_results,\n",
    "        'summary_df': results_df,\n",
    "        'report_path': report_path\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing folder: 47-22136 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 51-26987 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 54-1411 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 56-27847 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 58-38918 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 60-21851 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 60-25232 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 62-12734 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 62-2274 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 62-24379 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 62-26639 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 62-7533 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 63-15359 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 63-17862 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 63-17957 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 65-23331 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 66-12948 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 66-4559 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing folder: 66-700681 R\n",
      "--------------------------------------------------\n",
      "\n",
      "Analysis Complete!\n",
      "--------------------------------------------------\n",
      "Report saved to: D:\\Kananat\\TF_TMJOA_jpg_x_5px_test_batch_by_ID\\erosion_1\\analysis_report_20241224_063622.csv\n",
      "\n",
      "Summary of Results:\n",
      "         Folder  Final Class  Confidence Score  Total Images  Class 0 Count  Class 1 Count  Average Conf Class 0  Average Conf Class 1\n",
      "0    47-22136 R            1          0.987805            82              1             81              0.738926              0.984186\n",
      "1    51-26987 R            1          1.000000           122              0            122              0.000000              0.999975\n",
      "2     54-1411 R            1          1.000000           105              0            105              0.000000              0.991613\n",
      "3    56-27847 R            1          0.781513           119             26             93              0.812298              0.969669\n",
      "4    58-38918 R            0          0.907143           140            127             13              0.951106              0.677369\n",
      "5    60-21851 R            0          0.563107           103             58             45              0.905979              0.809711\n",
      "6    60-25232 R            0          0.666667            84             56             28              0.888064              0.795272\n",
      "7    62-12734 R            1          0.801527           131             26            105              0.821881              0.937653\n",
      "8     62-2274 R            1          0.981308           107              2            105              0.642212              0.986212\n",
      "9    62-24379 R            1          0.826772           127             22            105              0.864368              0.949479\n",
      "10   62-26639 R            0          0.629310           116             73             43              0.965733              0.964109\n",
      "11    62-7533 R            0          0.511111            90             46             44              0.938579              0.913151\n",
      "12   63-15359 R            1          0.723577           123             34             89              0.903829              0.954694\n",
      "13   63-17862 R            1          1.000000           113              0            113              0.000000              0.997309\n",
      "14   63-17957 R            1          0.951456           103              5             98              0.811536              0.982616\n",
      "15   65-23331 R            1          0.952756           127              6            121              0.791150              0.978411\n",
      "16   66-12948 R            0          0.971698           106            103              3              0.974589              0.606007\n",
      "17    66-4559 R            1          0.965116            86              3             83              0.904199              0.974776\n",
      "18  66-700681 R            1          0.841270           126             20            106              0.776938              0.981294\n",
      "\n",
      "Detailed Results by Folder:\n",
      "--------------------------------------------------\n",
      "\n",
      "Folder: 47-22136 R\n",
      "Final Class: 1\n",
      "Confidence Score: 98.78%\n",
      "Total Images Processed: 82\n",
      "Class Distribution: 0: 1, 1: 81\n",
      "\n",
      "Folder: 51-26987 R\n",
      "Final Class: 1\n",
      "Confidence Score: 100.00%\n",
      "Total Images Processed: 122\n",
      "Class Distribution: 0: 0, 1: 122\n",
      "\n",
      "Folder: 54-1411 R\n",
      "Final Class: 1\n",
      "Confidence Score: 100.00%\n",
      "Total Images Processed: 105\n",
      "Class Distribution: 0: 0, 1: 105\n",
      "\n",
      "Folder: 56-27847 R\n",
      "Final Class: 1\n",
      "Confidence Score: 78.15%\n",
      "Total Images Processed: 119\n",
      "Class Distribution: 0: 26, 1: 93\n",
      "\n",
      "Folder: 58-38918 R\n",
      "Final Class: 0\n",
      "Confidence Score: 90.71%\n",
      "Total Images Processed: 140\n",
      "Class Distribution: 0: 127, 1: 13\n",
      "\n",
      "Folder: 60-21851 R\n",
      "Final Class: 0\n",
      "Confidence Score: 56.31%\n",
      "Total Images Processed: 103\n",
      "Class Distribution: 0: 58, 1: 45\n",
      "\n",
      "Folder: 60-25232 R\n",
      "Final Class: 0\n",
      "Confidence Score: 66.67%\n",
      "Total Images Processed: 84\n",
      "Class Distribution: 0: 56, 1: 28\n",
      "\n",
      "Folder: 62-12734 R\n",
      "Final Class: 1\n",
      "Confidence Score: 80.15%\n",
      "Total Images Processed: 131\n",
      "Class Distribution: 0: 26, 1: 105\n",
      "\n",
      "Folder: 62-2274 R\n",
      "Final Class: 1\n",
      "Confidence Score: 98.13%\n",
      "Total Images Processed: 107\n",
      "Class Distribution: 0: 2, 1: 105\n",
      "\n",
      "Folder: 62-24379 R\n",
      "Final Class: 1\n",
      "Confidence Score: 82.68%\n",
      "Total Images Processed: 127\n",
      "Class Distribution: 0: 22, 1: 105\n",
      "\n",
      "Folder: 62-26639 R\n",
      "Final Class: 0\n",
      "Confidence Score: 62.93%\n",
      "Total Images Processed: 116\n",
      "Class Distribution: 0: 73, 1: 43\n",
      "\n",
      "Folder: 62-7533 R\n",
      "Final Class: 0\n",
      "Confidence Score: 51.11%\n",
      "Total Images Processed: 90\n",
      "Class Distribution: 0: 46, 1: 44\n",
      "\n",
      "Folder: 63-15359 R\n",
      "Final Class: 1\n",
      "Confidence Score: 72.36%\n",
      "Total Images Processed: 123\n",
      "Class Distribution: 0: 34, 1: 89\n",
      "\n",
      "Folder: 63-17862 R\n",
      "Final Class: 1\n",
      "Confidence Score: 100.00%\n",
      "Total Images Processed: 113\n",
      "Class Distribution: 0: 0, 1: 113\n",
      "\n",
      "Folder: 63-17957 R\n",
      "Final Class: 1\n",
      "Confidence Score: 95.15%\n",
      "Total Images Processed: 103\n",
      "Class Distribution: 0: 5, 1: 98\n",
      "\n",
      "Folder: 65-23331 R\n",
      "Final Class: 1\n",
      "Confidence Score: 95.28%\n",
      "Total Images Processed: 127\n",
      "Class Distribution: 0: 6, 1: 121\n",
      "\n",
      "Folder: 66-12948 R\n",
      "Final Class: 0\n",
      "Confidence Score: 97.17%\n",
      "Total Images Processed: 106\n",
      "Class Distribution: 0: 103, 1: 3\n",
      "\n",
      "Folder: 66-4559 R\n",
      "Final Class: 1\n",
      "Confidence Score: 96.51%\n",
      "Total Images Processed: 86\n",
      "Class Distribution: 0: 3, 1: 83\n",
      "\n",
      "Folder: 66-700681 R\n",
      "Final Class: 1\n",
      "Confidence Score: 84.13%\n",
      "Total Images Processed: 126\n",
      "Class Distribution: 0: 20, 1: 106\n"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "base_folder = r'D:\\Kananat\\TF_TMJOA_jpg_x_5px_test_batch_by_ID\\erosion_1'  # Replace with your folder path\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(r'C:\\Users\\kanan\\Desktop\\Project_TMJOA\\2D_Pipeline\\YOLO\\runs\\classify\\train\\weights\\best.pt')  # Replace with your model path\n",
    "\n",
    "# Run analysis\n",
    "results = analyze_multiple_folders(base_folder, model, confidence_threshold=0.5)\n",
    "\n",
    "# Print comprehensive results\n",
    "print(\"\\nAnalysis Complete!\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Report saved to: {results['report_path']}\")\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(results['summary_df'].to_string())\n",
    "\n",
    "# Print detailed statistics for each folder\n",
    "print(\"\\nDetailed Results by Folder:\")\n",
    "print(\"-\" * 50)\n",
    "for folder_name, folder_data in results['folder_results'].items():\n",
    "    if 'error' in folder_data:\n",
    "        print(f\"\\n{folder_name}: Error - {folder_data['error']}\")\n",
    "        continue\n",
    "        \n",
    "    final_result = folder_data['final_result']\n",
    "    stats = final_result['detailed_stats']\n",
    "    \n",
    "    print(f\"\\nFolder: {folder_name}\")\n",
    "    print(f\"Final Class: {final_result['final_class']}\")\n",
    "    print(f\"Confidence Score: {final_result['confidence_score']:.2%}\")\n",
    "    print(f\"Total Images Processed: {stats['total_predictions']}\")\n",
    "    print(f\"Class Distribution: 0: {stats['class_counts'][0]}, \"\n",
    "            f\"1: {stats['class_counts'][1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IGB0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
