{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6203d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import copy\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ddf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVLogger:\n",
    "    \"\"\"\n",
    "    CSV Logger for training metrics - similar to Keras CSVLogger\n",
    "    \"\"\"\n",
    "    def __init__(self, filename='training_log.csv', separator=',', append=False):\n",
    "        \"\"\"\n",
    "        Initialize CSV Logger\n",
    "        \n",
    "        Args:\n",
    "            filename: Name of the CSV file\n",
    "            separator: Separator character (default: comma)\n",
    "            append: Whether to append to existing file or overwrite\n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "        self.separator = separator\n",
    "        self.append = append\n",
    "        self.keys = None\n",
    "        self.file_exists = os.path.isfile(filename) and append\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(filename) if os.path.dirname(filename) else '.', exist_ok=True)\n",
    "        \n",
    "        if not self.file_exists:\n",
    "            # Create new file with headers\n",
    "            self.file = open(filename, 'w', newline='', encoding='utf-8')\n",
    "            self.writer = None\n",
    "        else:\n",
    "            # Append to existing file\n",
    "            self.file = open(filename, 'a', newline='', encoding='utf-8')\n",
    "            self.writer = csv.writer(self.file, delimiter=self.separator)\n",
    "    \n",
    "    def log(self, logs):\n",
    "        \"\"\"\n",
    "        Log metrics to CSV file\n",
    "        \n",
    "        Args:\n",
    "            logs: Dictionary of metrics to log\n",
    "        \"\"\"\n",
    "        if self.keys is None:\n",
    "            self.keys = sorted(logs.keys())\n",
    "            self.writer = csv.DictWriter(self.file, fieldnames=self.keys, delimiter=self.separator)\n",
    "            if not self.file_exists:\n",
    "                self.writer.writeheader()\n",
    "        \n",
    "        # Write the row\n",
    "        self.writer.writerow(logs)\n",
    "        self.file.flush()\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close the CSV file\"\"\"\n",
    "        if hasattr(self, 'file'):\n",
    "            self.file.close()\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7022406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Data paths - UPDATE THESE PATHS\n",
    "    data_root = r\"D:\\Kananat\\Data\\training_dataset\"  # Update this path\n",
    "    train_dir = os.path.join(data_root, \"train\")\n",
    "    val_dir = os.path.join(data_root, \"val\") \n",
    "    test_dir = os.path.join(data_root, \"test\")\n",
    "    \n",
    "    # Training parameters\n",
    "    batch_size = 2  # Small batch size for 3D data due to memory constraints\n",
    "    num_epochs = 100\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 1e-5\n",
    "    \n",
    "    # Model parameters\n",
    "    input_size = (224, 224, 224)\n",
    "    num_classes = 2\n",
    "    \n",
    "    # Training settings\n",
    "    patience = 25  # Early stopping patience\n",
    "    save_best_model = True\n",
    "    model_save_path = r\"C:\\Users\\kanan\\Desktop\\Project_TMJOA\\3D_Pipeline\\densenet121_tiny_nonrotate_augment\\densenet121_tiny_best.pth\"\n",
    "    \n",
    "    # CSV Logging\n",
    "    csv_log_path = r\"C:\\Users\\kanan\\Desktop\\Project_TMJOA\\3D_Pipeline\\densenet121_tiny_nonrotate_augment\\densenet121_tiny_history.csv\"\n",
    "    log_detailed_metrics = True  # Log additional metrics like learning rate, epoch time\n",
    "    \n",
    "    # Monitoring\n",
    "    print_freq = 1\n",
    "    plot_losses = True\n",
    "\n",
    "    # Backbone\n",
    "    backbone = \"convnext_tiny\"  # Backbone model to use\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec8090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Medical3DDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, target_size=(224, 224, 224)):\n",
    "        \"\"\"\n",
    "        Dataset for 3D medical images in .nii.gz format\n",
    "        \n",
    "        Args:\n",
    "            data_dir: Directory containing class folders\n",
    "            transform: Data augmentation function (if provided)\n",
    "            target_size: Target size for resizing (224, 224, 224)\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        \n",
    "        # Get class folders\n",
    "        class_folders = [d for d in os.listdir(data_dir) \n",
    "                        if os.path.isdir(os.path.join(data_dir, d))]\n",
    "        class_folders.sort()\n",
    "        \n",
    "        # Create class to index mapping\n",
    "        for idx, class_name in enumerate(class_folders):\n",
    "            self.class_to_idx[class_name] = idx\n",
    "            \n",
    "        # Collect all samples\n",
    "        for class_name in class_folders:\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            \n",
    "            # Find all .nii.gz files\n",
    "            nii_files = glob.glob(os.path.join(class_dir, \"*.nii.gz\"))\n",
    "            \n",
    "            for file_path in nii_files:\n",
    "                self.samples.append((file_path, class_idx))\n",
    "                \n",
    "        print(f\"Found {len(self.samples)} samples in {len(class_folders)} classes\")\n",
    "        print(f\"Classes: {self.class_to_idx}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.samples[idx]\n",
    "        \n",
    "        # Load .nii.gz file\n",
    "        nii_img = nib.load(file_path)\n",
    "        image = nii_img.get_fdata()\n",
    "        \n",
    "        # Convert to float32\n",
    "        image = image.astype(np.float32)\n",
    "        \n",
    "        # Resize from (255, 255, 255) to (224, 224, 224)\n",
    "        image = self.resize_3d(image, self.target_size)\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        if image.max() > image.min():\n",
    "            image = (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "        # Apply data augmentation if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            image = image.astype(np.float32)\n",
    "\n",
    "        if image.max() > image.min():\n",
    "            image = (image - image.min()) / (image.max() - image.min())\n",
    "        \n",
    "        # Add channel dimension and convert to tensor\n",
    "        image = torch.from_numpy(image).unsqueeze(0)  # Shape: (1, 224, 224, 224)\n",
    "            \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "    def resize_3d(self, image, target_size):\n",
    "        \"\"\"\n",
    "        Resize 3D image from (255, 255, 255) to target_size using interpolation\n",
    "        \"\"\"\n",
    "        from scipy.ndimage import zoom\n",
    "        \n",
    "        current_size = image.shape\n",
    "        zoom_factors = [target_size[i] / current_size[i] for i in range(3)]\n",
    "        \n",
    "        # Use order=1 for linear interpolation (good balance of speed and quality)\n",
    "        resized_image = zoom(image, zoom_factors, order=1)\n",
    "        \n",
    "        return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import volumentations\n",
    "\n",
    "def get_augmentation(patch_size):\n",
    "    return volumentations.Compose([\n",
    "        # volumentations.Rotate((-10, 10), (0, 0), (0, 0), p=0.5),\n",
    "        # volumentations.Rotate((0, 0), (-10, 10), (0, 0), p=0.5),\n",
    "        # volumentations.Rotate((0, 0), (0, 0), (-10, 10), p=0.5),\n",
    "        volumentations.RandomCropFromBorders(crop_value=0.1, p=0.5),\n",
    "        volumentations.ElasticTransform((0, 0.25), interpolation=2, p=0.1),\n",
    "        volumentations.Resize(patch_size, interpolation=1, resize_type=0, always_apply=True, p=1.0),\n",
    "        # volumentations.Flip(0, p=0.5),\n",
    "        # volumentations.Flip(1, p=0.5),\n",
    "        # volumentations.Flip(2, p=0.5),\n",
    "        # volumentations.RandomRotate90((1, 2), p=0.5),\n",
    "        volumentations.GaussianNoise(var_limit=(0, 5), p=0.2),\n",
    "        # volumentations.RandomGamma(gamma_limit=(80, 120), p=0.2),\n",
    "    ], p=1.0)\n",
    "\n",
    "def augment_volume(volume):\n",
    "\n",
    "    augment = get_augmentation(volume.shape)\n",
    "    augmented_volume = augment(image=volume)[\"image\"]\n",
    "    \n",
    "    return augmented_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30831f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(config, train_transform=None, val_transform=None):\n",
    "    \"\"\"Create train, validation, and test data loaders\"\"\"\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = Medical3DDataset(config.train_dir, transform=train_transform)\n",
    "    val_dataset = Medical3DDataset(config.val_dir, transform=val_transform)\n",
    "    test_dataset = Medical3DDataset(config.test_dir, transform=val_transform)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_dataset.class_to_idx\n",
    "\n",
    "# Create data loaders\n",
    "# Note: Pass your data augmentation function as train_transform if you have one\n",
    "# Example: train_loader, val_loader, test_loader, class_to_idx = create_data_loaders(config, train_transform=your_augmentation_function)\n",
    "train_loader, val_loader, test_loader, class_to_idx = create_data_loaders(config, train_transform=augment_volume)\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92789b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch, config):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config.num_epochs}')\n",
    "    \n",
    "    for batch_idx, (inputs, labels) in enumerate(progress_bar):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        total_samples += inputs.size(0)\n",
    "        \n",
    "        # Update progress bar\n",
    "        if batch_idx % config.print_freq == 0:\n",
    "            current_loss = running_loss / total_samples\n",
    "            current_acc = running_corrects.double() / total_samples\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{current_loss:.4f}',\n",
    "                'Acc': f'{current_acc:.4f}'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects.double() / total_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b5700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc='Validating'):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total_samples += inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects.double() / total_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1913b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, config):\n",
    "    \"\"\"Main training function with CSV logging\"\"\"\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "    \n",
    "    # Initialize CSV Logger\n",
    "    csv_logger = CSVLogger(config.csv_log_path, append=False)\n",
    "    \n",
    "    # Training history\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    # Early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    print(f\"Metrics will be logged to: {config.csv_log_path}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(config.num_epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch, config)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "            \n",
    "            # Get current learning rate\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Update scheduler\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # Save history\n",
    "            train_losses.append(train_loss)\n",
    "            train_accs.append(train_acc)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accs.append(val_acc)\n",
    "            \n",
    "            epoch_time = time.time() - epoch_start_time\n",
    "            \n",
    "            # Prepare metrics for CSV logging\n",
    "            metrics = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'train_accuracy': train_acc,\n",
    "                'val_loss': val_loss,\n",
    "                'val_accuracy': val_acc,\n",
    "                'learning_rate': current_lr,\n",
    "                'epoch_time': epoch_time,\n",
    "                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            }\n",
    "            \n",
    "            # Add additional metrics if enabled\n",
    "            if config.log_detailed_metrics:\n",
    "                metrics.update({\n",
    "                    'best_val_loss': best_val_loss if val_loss >= best_val_loss else val_loss,\n",
    "                    'patience_counter': patience_counter,\n",
    "                    'is_best_epoch': val_loss < best_val_loss\n",
    "                })\n",
    "            \n",
    "            # Log to CSV\n",
    "            csv_logger.log(metrics)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{config.num_epochs}:')\n",
    "            print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "            print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "            print(f'  Learning Rate: {current_lr:.2e}')\n",
    "            print(f'  Time: {epoch_time:.2f}s')\n",
    "            print('-' * 50)\n",
    "            \n",
    "            # Early stopping and best model saving\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                patience_counter = 0\n",
    "                \n",
    "                if config.save_best_model:\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'best_val_loss': best_val_loss,\n",
    "                        'train_losses': train_losses,\n",
    "                        'val_losses': val_losses,\n",
    "                        'train_accs': train_accs,\n",
    "                        'val_accs': val_accs,\n",
    "                        'class_to_idx': class_to_idx\n",
    "                    }, config.model_save_path)\n",
    "                    print(f'Best model saved to {config.model_save_path}')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= config.patience:\n",
    "                print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "                break\n",
    "                \n",
    "    finally:\n",
    "        # Always close the CSV logger\n",
    "        csv_logger.close()\n",
    "    \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accs': val_accs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d49b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm_3d\n",
    "from torchinfo import summary\n",
    "\n",
    "model = timm_3d.create_model(\n",
    "    'densenet121',\n",
    "    pretrained=False,\n",
    "    num_classes=2\n",
    ")\n",
    "\n",
    "model.features.conv0 = nn.Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
    "\n",
    "# print(model)\n",
    "\n",
    "summary(model, input_size=(4, 1, 224, 224, 224)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b67b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model, history = train_model(model, train_loader, val_loader, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dmodel_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
