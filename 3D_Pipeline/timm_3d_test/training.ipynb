{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6203d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import copy\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72ddf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba73698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVLogger:\n",
    "    \"\"\"\n",
    "    CSV Logger for training metrics - similar to Keras CSVLogger\n",
    "    \"\"\"\n",
    "    def __init__(self, filename='training_log.csv', separator=',', append=False):\n",
    "        \"\"\"\n",
    "        Initialize CSV Logger\n",
    "        \n",
    "        Args:\n",
    "            filename: Name of the CSV file\n",
    "            separator: Separator character (default: comma)\n",
    "            append: Whether to append to existing file or overwrite\n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "        self.separator = separator\n",
    "        self.append = append\n",
    "        self.keys = None\n",
    "        self.file_exists = os.path.isfile(filename) and append\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(filename) if os.path.dirname(filename) else '.', exist_ok=True)\n",
    "        \n",
    "        if not self.file_exists:\n",
    "            # Create new file with headers\n",
    "            self.file = open(filename, 'w', newline='', encoding='utf-8')\n",
    "            self.writer = None\n",
    "        else:\n",
    "            # Append to existing file\n",
    "            self.file = open(filename, 'a', newline='', encoding='utf-8')\n",
    "            self.writer = csv.writer(self.file, delimiter=self.separator)\n",
    "    \n",
    "    def log(self, logs):\n",
    "        \"\"\"\n",
    "        Log metrics to CSV file\n",
    "        \n",
    "        Args:\n",
    "            logs: Dictionary of metrics to log\n",
    "        \"\"\"\n",
    "        if self.keys is None:\n",
    "            self.keys = sorted(logs.keys())\n",
    "            self.writer = csv.DictWriter(self.file, fieldnames=self.keys, delimiter=self.separator)\n",
    "            if not self.file_exists:\n",
    "                self.writer.writeheader()\n",
    "        \n",
    "        # Write the row\n",
    "        self.writer.writerow(logs)\n",
    "        self.file.flush()\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close the CSV file\"\"\"\n",
    "        if hasattr(self, 'file'):\n",
    "            self.file.close()\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7022406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Data paths - UPDATE THESE PATHS\n",
    "    data_root = r\"C:\\Users\\acer\\Desktop\\Project_TMJOA\\Data\\training_dataset\"  # Update this path\n",
    "    train_dir = os.path.join(data_root, \"train\")\n",
    "    val_dir = os.path.join(data_root, \"val\") \n",
    "    test_dir = os.path.join(data_root, \"test\")\n",
    "    \n",
    "    # Training parameters\n",
    "    batch_size = 2  # Small batch size for 3D data due to memory constraints\n",
    "    num_epochs = 50\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 1e-5\n",
    "    \n",
    "    # Model parameters\n",
    "    input_size = (224, 224, 224)\n",
    "    num_classes = 2\n",
    "    \n",
    "    # Training settings\n",
    "    patience = 10  # Early stopping patience\n",
    "    save_best_model = True\n",
    "    model_save_path = \"resnet18_3d_best.pth\"\n",
    "    \n",
    "    # CSV Logging\n",
    "    csv_log_path = \"resnet18_3d_best_history.csv\"\n",
    "    log_detailed_metrics = True  # Log additional metrics like learning rate, epoch time\n",
    "    \n",
    "    # Monitoring\n",
    "    print_freq = 10\n",
    "    plot_losses = True\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ec8090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Medical3DDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, target_size=(224, 224, 224)):\n",
    "        \"\"\"\n",
    "        Dataset for 3D medical images in .nii.gz format\n",
    "        \n",
    "        Args:\n",
    "            data_dir: Directory containing class folders\n",
    "            transform: Data augmentation function (if provided)\n",
    "            target_size: Target size for resizing (224, 224, 224)\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        \n",
    "        # Get class folders\n",
    "        class_folders = [d for d in os.listdir(data_dir) \n",
    "                        if os.path.isdir(os.path.join(data_dir, d))]\n",
    "        class_folders.sort()\n",
    "        \n",
    "        # Create class to index mapping\n",
    "        for idx, class_name in enumerate(class_folders):\n",
    "            self.class_to_idx[class_name] = idx\n",
    "            \n",
    "        # Collect all samples\n",
    "        for class_name in class_folders:\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            \n",
    "            # Find all .nii.gz files\n",
    "            nii_files = glob.glob(os.path.join(class_dir, \"*.nii.gz\"))\n",
    "            \n",
    "            for file_path in nii_files:\n",
    "                self.samples.append((file_path, class_idx))\n",
    "                \n",
    "        print(f\"Found {len(self.samples)} samples in {len(class_folders)} classes\")\n",
    "        print(f\"Classes: {self.class_to_idx}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.samples[idx]\n",
    "        \n",
    "        # Load .nii.gz file\n",
    "        nii_img = nib.load(file_path)\n",
    "        image = nii_img.get_fdata()\n",
    "        \n",
    "        # Convert to float32\n",
    "        image = image.astype(np.float32)\n",
    "        \n",
    "        # Resize from (255, 255, 255) to (224, 224, 224)\n",
    "        image = self.resize_3d(image, self.target_size)\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        if image.max() > image.min():\n",
    "            image = (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "        # Apply data augmentation if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            image = image.astype(np.float32)\n",
    "        \n",
    "        # Add channel dimension and convert to tensor\n",
    "        image = torch.from_numpy(image).unsqueeze(0)  # Shape: (1, 224, 224, 224)\n",
    "            \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "    def resize_3d(self, image, target_size):\n",
    "        \"\"\"\n",
    "        Resize 3D image from (255, 255, 255) to target_size using interpolation\n",
    "        \"\"\"\n",
    "        from scipy.ndimage import zoom\n",
    "        \n",
    "        current_size = image.shape\n",
    "        zoom_factors = [target_size[i] / current_size[i] for i in range(3)]\n",
    "        \n",
    "        # Use order=1 for linear interpolation (good balance of speed and quality)\n",
    "        resized_image = zoom(image, zoom_factors, order=1)\n",
    "        \n",
    "        return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbeb5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import volumentations\n",
    "\n",
    "def get_augmentation(patch_size):\n",
    "    return volumentations.Compose([\n",
    "        volumentations.Rotate((-15, 15), (0, 0), (0, 0), p=0.5),\n",
    "        volumentations.RandomCropFromBorders(crop_value=0.1, p=0.5),\n",
    "        volumentations.ElasticTransform((0, 0.25), interpolation=2, p=0.1),\n",
    "        volumentations.Resize(patch_size, interpolation=1, resize_type=0, always_apply=True, p=1.0),\n",
    "        volumentations.Flip(0, p=0.5),\n",
    "        volumentations.Flip(1, p=0.5),\n",
    "        volumentations.Flip(2, p=0.5),\n",
    "        volumentations.RandomRotate90((1, 2), p=0.5),\n",
    "        volumentations.GaussianNoise(var_limit=(0, 5), p=0.2),\n",
    "        volumentations.RandomGamma(gamma_limit=(80, 120), p=0.2),\n",
    "    ], p=1.0)\n",
    "\n",
    "def augment_volume(volume):\n",
    "\n",
    "    augment = get_augmentation(volume.shape)\n",
    "    augmented_volume = augment(image=volume)[\"image\"]\n",
    "    \n",
    "    return augmented_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30831f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 254 samples in 2 classes\n",
      "Classes: {'0': 0, '1': 1}\n",
      "Found 73 samples in 2 classes\n",
      "Classes: {'0': 0, '1': 1}\n",
      "Found 37 samples in 2 classes\n",
      "Classes: {'0': 0, '1': 1}\n",
      "Train batches: 127\n",
      "Val batches: 37\n",
      "Test batches: 19\n"
     ]
    }
   ],
   "source": [
    "def create_data_loaders(config, train_transform=None, val_transform=None):\n",
    "    \"\"\"Create train, validation, and test data loaders\"\"\"\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = Medical3DDataset(config.train_dir, transform=train_transform)\n",
    "    val_dataset = Medical3DDataset(config.val_dir, transform=val_transform)\n",
    "    test_dataset = Medical3DDataset(config.test_dir, transform=val_transform)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_dataset.class_to_idx\n",
    "\n",
    "# Create data loaders\n",
    "# Note: Pass your data augmentation function as train_transform if you have one\n",
    "# Example: train_loader, val_loader, test_loader, class_to_idx = create_data_loaders(config, train_transform=your_augmentation_function)\n",
    "train_loader, val_loader, test_loader, class_to_idx = create_data_loaders(config, train_transform=augment_volume)\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92789b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch, config):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config.num_epochs}')\n",
    "    \n",
    "    for batch_idx, (inputs, labels) in enumerate(progress_bar):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        total_samples += inputs.size(0)\n",
    "        \n",
    "        # Update progress bar\n",
    "        if batch_idx % config.print_freq == 0:\n",
    "            current_loss = running_loss / total_samples\n",
    "            current_acc = running_corrects.double() / total_samples\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{current_loss:.4f}',\n",
    "                'Acc': f'{current_acc:.4f}'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects.double() / total_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03b5700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc='Validating'):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total_samples += inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects.double() / total_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1913b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, config):\n",
    "    \"\"\"Main training function with CSV logging\"\"\"\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "    \n",
    "    # Initialize CSV Logger\n",
    "    csv_logger = CSVLogger(config.csv_log_path, append=False)\n",
    "    \n",
    "    # Training history\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    # Early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    print(f\"Metrics will be logged to: {config.csv_log_path}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(config.num_epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch, config)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "            \n",
    "            # Get current learning rate\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Update scheduler\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # Save history\n",
    "            train_losses.append(train_loss)\n",
    "            train_accs.append(train_acc)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accs.append(val_acc)\n",
    "            \n",
    "            epoch_time = time.time() - epoch_start_time\n",
    "            \n",
    "            # Prepare metrics for CSV logging\n",
    "            metrics = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'train_accuracy': train_acc,\n",
    "                'val_loss': val_loss,\n",
    "                'val_accuracy': val_acc,\n",
    "                'learning_rate': current_lr,\n",
    "                'epoch_time': epoch_time,\n",
    "                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            }\n",
    "            \n",
    "            # Add additional metrics if enabled\n",
    "            if config.log_detailed_metrics:\n",
    "                metrics.update({\n",
    "                    'best_val_loss': best_val_loss if val_loss >= best_val_loss else val_loss,\n",
    "                    'patience_counter': patience_counter,\n",
    "                    'is_best_epoch': val_loss < best_val_loss\n",
    "                })\n",
    "            \n",
    "            # Log to CSV\n",
    "            csv_logger.log(metrics)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{config.num_epochs}:')\n",
    "            print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "            print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "            print(f'  Learning Rate: {current_lr:.2e}')\n",
    "            print(f'  Time: {epoch_time:.2f}s')\n",
    "            print('-' * 50)\n",
    "            \n",
    "            # Early stopping and best model saving\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                patience_counter = 0\n",
    "                \n",
    "                if config.save_best_model:\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'best_val_loss': best_val_loss,\n",
    "                        'train_losses': train_losses,\n",
    "                        'val_losses': val_losses,\n",
    "                        'train_accs': train_accs,\n",
    "                        'val_accs': val_accs,\n",
    "                        'class_to_idx': class_to_idx\n",
    "                    }, config.model_save_path)\n",
    "                    print(f'Best model saved to {config.model_save_path}')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= config.patience:\n",
    "                print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "                break\n",
    "                \n",
    "    finally:\n",
    "        # Always close the CSV logger\n",
    "        csv_logger.close()\n",
    "    \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accs': val_accs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d49b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Trainable\n",
       "============================================================================================================================================\n",
       "ResNet                                   [1, 1, 224, 224, 224]     [1, 2]                    --                        True\n",
       "├─Conv3d: 1-1                            [1, 1, 224, 224, 224]     [1, 64, 112, 112, 112]    21,952                    True\n",
       "├─BatchNorm3d: 1-2                       [1, 64, 112, 112, 112]    [1, 64, 112, 112, 112]    128                       True\n",
       "├─ReLU: 1-3                              [1, 64, 112, 112, 112]    [1, 64, 112, 112, 112]    --                        --\n",
       "├─MaxPool3d: 1-4                         [1, 64, 112, 112, 112]    [1, 64, 56, 56, 56]       --                        --\n",
       "├─Sequential: 1-5                        [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       --                        True\n",
       "│    └─BasicBlock: 2-1                   [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       --                        True\n",
       "│    │    └─Conv3d: 3-1                  [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       110,592                   True\n",
       "│    │    └─BatchNorm3d: 3-2             [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       128                       True\n",
       "│    │    └─Identity: 3-3                [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       --                        --\n",
       "│    │    └─ReLU: 3-4                    [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       --                        --\n",
       "│    │    └─Identity: 3-5                [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       --                        --\n",
       "│    │    └─Conv3d: 3-6                  [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       110,592                   True\n",
       "│    │    └─BatchNorm3d: 3-7             [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       128                       True\n",
       "│    │    └─ReLU: 3-8                    [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       --                        --\n",
       "│    └─BasicBlock: 2-2                   [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       --                        True\n",
       "│    │    └─Conv3d: 3-9                  [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       110,592                   True\n",
       "│    │    └─BatchNorm3d: 3-10            [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       128                       True\n",
       "│    │    └─Identity: 3-11               [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       --                        --\n",
       "│    │    └─ReLU: 3-12                   [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       --                        --\n",
       "│    │    └─Identity: 3-13               [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       --                        --\n",
       "│    │    └─Conv3d: 3-14                 [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       110,592                   True\n",
       "│    │    └─BatchNorm3d: 3-15            [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       128                       True\n",
       "│    │    └─ReLU: 3-16                   [1, 64, 56, 56, 56]       [1, 64, 56, 56, 56]       --                        --\n",
       "├─Sequential: 1-6                        [1, 64, 56, 56, 56]       [1, 128, 28, 28, 28]      --                        True\n",
       "│    └─BasicBlock: 2-3                   [1, 64, 56, 56, 56]       [1, 128, 28, 28, 28]      --                        True\n",
       "│    │    └─Conv3d: 3-17                 [1, 64, 56, 56, 56]       [1, 128, 28, 28, 28]      221,184                   True\n",
       "│    │    └─BatchNorm3d: 3-18            [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      256                       True\n",
       "│    │    └─Identity: 3-19               [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      --                        --\n",
       "│    │    └─ReLU: 3-20                   [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      --                        --\n",
       "│    │    └─Identity: 3-21               [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      --                        --\n",
       "│    │    └─Conv3d: 3-22                 [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      442,368                   True\n",
       "│    │    └─BatchNorm3d: 3-23            [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      256                       True\n",
       "│    │    └─Sequential: 3-24             [1, 64, 56, 56, 56]       [1, 128, 28, 28, 28]      8,448                     True\n",
       "│    │    └─ReLU: 3-25                   [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      --                        --\n",
       "│    └─BasicBlock: 2-4                   [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      --                        True\n",
       "│    │    └─Conv3d: 3-26                 [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      442,368                   True\n",
       "│    │    └─BatchNorm3d: 3-27            [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      256                       True\n",
       "│    │    └─Identity: 3-28               [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      --                        --\n",
       "│    │    └─ReLU: 3-29                   [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      --                        --\n",
       "│    │    └─Identity: 3-30               [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      --                        --\n",
       "│    │    └─Conv3d: 3-31                 [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      442,368                   True\n",
       "│    │    └─BatchNorm3d: 3-32            [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      256                       True\n",
       "│    │    └─ReLU: 3-33                   [1, 128, 28, 28, 28]      [1, 128, 28, 28, 28]      --                        --\n",
       "├─Sequential: 1-7                        [1, 128, 28, 28, 28]      [1, 256, 14, 14, 14]      --                        True\n",
       "│    └─BasicBlock: 2-5                   [1, 128, 28, 28, 28]      [1, 256, 14, 14, 14]      --                        True\n",
       "│    │    └─Conv3d: 3-34                 [1, 128, 28, 28, 28]      [1, 256, 14, 14, 14]      884,736                   True\n",
       "│    │    └─BatchNorm3d: 3-35            [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      512                       True\n",
       "│    │    └─Identity: 3-36               [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      --                        --\n",
       "│    │    └─ReLU: 3-37                   [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      --                        --\n",
       "│    │    └─Identity: 3-38               [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      --                        --\n",
       "│    │    └─Conv3d: 3-39                 [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      1,769,472                 True\n",
       "│    │    └─BatchNorm3d: 3-40            [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      512                       True\n",
       "│    │    └─Sequential: 3-41             [1, 128, 28, 28, 28]      [1, 256, 14, 14, 14]      33,280                    True\n",
       "│    │    └─ReLU: 3-42                   [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      --                        --\n",
       "│    └─BasicBlock: 2-6                   [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      --                        True\n",
       "│    │    └─Conv3d: 3-43                 [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      1,769,472                 True\n",
       "│    │    └─BatchNorm3d: 3-44            [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      512                       True\n",
       "│    │    └─Identity: 3-45               [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      --                        --\n",
       "│    │    └─ReLU: 3-46                   [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      --                        --\n",
       "│    │    └─Identity: 3-47               [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      --                        --\n",
       "│    │    └─Conv3d: 3-48                 [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      1,769,472                 True\n",
       "│    │    └─BatchNorm3d: 3-49            [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      512                       True\n",
       "│    │    └─ReLU: 3-50                   [1, 256, 14, 14, 14]      [1, 256, 14, 14, 14]      --                        --\n",
       "├─Sequential: 1-8                        [1, 256, 14, 14, 14]      [1, 512, 7, 7, 7]         --                        True\n",
       "│    └─BasicBlock: 2-7                   [1, 256, 14, 14, 14]      [1, 512, 7, 7, 7]         --                        True\n",
       "│    │    └─Conv3d: 3-51                 [1, 256, 14, 14, 14]      [1, 512, 7, 7, 7]         3,538,944                 True\n",
       "│    │    └─BatchNorm3d: 3-52            [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         1,024                     True\n",
       "│    │    └─Identity: 3-53               [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         --                        --\n",
       "│    │    └─ReLU: 3-54                   [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         --                        --\n",
       "│    │    └─Identity: 3-55               [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         --                        --\n",
       "│    │    └─Conv3d: 3-56                 [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         7,077,888                 True\n",
       "│    │    └─BatchNorm3d: 3-57            [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         1,024                     True\n",
       "│    │    └─Sequential: 3-58             [1, 256, 14, 14, 14]      [1, 512, 7, 7, 7]         132,096                   True\n",
       "│    │    └─ReLU: 3-59                   [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         --                        --\n",
       "│    └─BasicBlock: 2-8                   [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         --                        True\n",
       "│    │    └─Conv3d: 3-60                 [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         7,077,888                 True\n",
       "│    │    └─BatchNorm3d: 3-61            [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         1,024                     True\n",
       "│    │    └─Identity: 3-62               [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         --                        --\n",
       "│    │    └─ReLU: 3-63                   [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         --                        --\n",
       "│    │    └─Identity: 3-64               [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         --                        --\n",
       "│    │    └─Conv3d: 3-65                 [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         7,077,888                 True\n",
       "│    │    └─BatchNorm3d: 3-66            [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         1,024                     True\n",
       "│    │    └─ReLU: 3-67                   [1, 512, 7, 7, 7]         [1, 512, 7, 7, 7]         --                        --\n",
       "├─SelectAdaptivePool3d: 1-9              [1, 512, 7, 7, 7]         [1, 512]                  --                        --\n",
       "│    └─AdaptiveAvgPool3d: 2-9            [1, 512, 7, 7, 7]         [1, 512, 1, 1, 1]         --                        --\n",
       "│    └─Flatten: 2-10                     [1, 512, 1, 1, 1]         [1, 512]                  --                        --\n",
       "├─Linear: 1-10                           [1, 512]                  [1, 2]                    1,026                     True\n",
       "============================================================================================================================================\n",
       "Total params: 33,161,026\n",
       "Trainable params: 33,161,026\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 168.32\n",
       "============================================================================================================================================\n",
       "Input size (MB): 44.96\n",
       "Forward/backward pass size (MB): 2453.00\n",
       "Params size (MB): 132.64\n",
       "Estimated Total Size (MB): 2630.61\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm_3d\n",
    "from torchinfo import summary\n",
    "\n",
    "model = timm_3d.create_model(\n",
    "    'resnet18.a1_in1k',\n",
    "    pretrained=False,\n",
    "    num_classes=2\n",
    ")\n",
    "\n",
    "model.conv1 = nn.Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
    "\n",
    "summary(model,input_size=(1, 1, 224, 224, 224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b67b136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Metrics will be logged to: resnet18_3d_best_history.csv\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0220520b35400f858c7667f29b331d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\volumentations\\augmentations\\functional.py:243: RuntimeWarning: invalid value encountered in power\n",
      "  img = np.power(img, gamma)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trained_model, history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, config)\u001b[39m\n\u001b[32m     34\u001b[39m epoch_start_time = time.time()\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m     40\u001b[39m val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, device, epoch, config)\u001b[39m\n\u001b[32m      6\u001b[39m total_samples = \u001b[32m0\u001b[39m\n\u001b[32m      8\u001b[39m progress_bar = tqdm(train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.num_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\tqdm\\notebook.py:250\u001b[39m, in \u001b[36mtqdm_notebook.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    249\u001b[39m     it = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mMedical3DDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Apply data augmentation if provided\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     image = image.astype(np.float32)\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Add channel dimension and convert to tensor\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36maugment_volume\u001b[39m\u001b[34m(volume)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maugment_volume\u001b[39m(volume):\n\u001b[32m     19\u001b[39m     augment = get_augmentation(volume.shape)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     augmented_volume = \u001b[43maugment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvolume\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m augmented_volume\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\volumentations\\core\\composition.py:60\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, force_apply, **data)\u001b[39m\n\u001b[32m     57\u001b[39m transforms = \u001b[38;5;28mself\u001b[39m.transforms \u001b[38;5;28;01mif\u001b[39;00m need_to_run \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_always_apply_transforms()\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tr \u001b[38;5;129;01min\u001b[39;00m transforms:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     data = \u001b[43mtr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce_apply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\volumentations\\core\\transforms_interface.py:84\u001b[39m, in \u001b[36mTransform.__call__\u001b[39m\u001b[34m(self, force_apply, targets, **data)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, force_apply, targets, **data):\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m force_apply \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.always_apply \u001b[38;5;129;01mor\u001b[39;00m random.random() < \u001b[38;5;28mself\u001b[39m.p:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m         params = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m VERBOSE:\n\u001b[32m     87\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mRUN\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\volumentations\\augmentations\\transforms.py:84\u001b[39m, in \u001b[36mGaussianNoise.get_params\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m     81\u001b[39m var = uniform(\u001b[38;5;28mself\u001b[39m.var_limit[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.var_limit[\u001b[32m1\u001b[39m])\n\u001b[32m     82\u001b[39m sigma = var ** \u001b[32m0.5\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m gauss = \u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mgauss\u001b[39m\u001b[33m\"\u001b[39m: gauss}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\volumentations\\random_utils.py:77\u001b[39m, in \u001b[36mnormal\u001b[39m\u001b[34m(loc, scale, size, random_state)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m random_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     76\u001b[39m     random_state = get_random_state()\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trained_model, history = train_model(model, train_loader, val_loader, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
