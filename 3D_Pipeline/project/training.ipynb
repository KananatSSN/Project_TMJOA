{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb6c786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchIO available for medical augmentations\n",
      "MONAI available for medical networks\n",
      "Using device: cpu\n",
      "Configuration loaded successfully\n",
      "Input size: (254, 254, 254)\n",
      "Batch size: 4\n",
      "Learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Block 1: Dependencies and Setup\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Medical imaging libraries\n",
    "try:\n",
    "    import torchio as tio\n",
    "    print(\"TorchIO available for medical augmentations\")\n",
    "except ImportError:\n",
    "    print(\"TorchIO not found. Install with: pip install torchio\")\n",
    "    tio = None\n",
    "\n",
    "try:\n",
    "    import monai\n",
    "    from monai.networks.nets import ResNet\n",
    "    from monai.transforms import (\n",
    "        Compose, LoadImage, ScaleIntensity, RandRotate, RandFlip,\n",
    "        RandGaussianNoise, RandBiasField, Rand3DElastic\n",
    "    )\n",
    "    print(\"MONAI available for medical networks\")\n",
    "except ImportError:\n",
    "    print(\"MONAI not found. Install with: pip install monai\")\n",
    "    monai = None\n",
    "\n",
    "# Set device and random seeds for reproducibility\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'data_path': r\"C:\\Users\\acer\\Desktop\\Project_TMJOA\\Data\\training_dataset_3D\",  # Update this to your data path\n",
    "    'batch_size': 4,  # Small batch size for 3D volumes\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_epochs': 100,\n",
    "    'early_stopping_patience': 20,\n",
    "    'num_folds': 5,\n",
    "    'input_size': (254, 254, 254),  # Adjust based on your data\n",
    "    'num_classes': 2,\n",
    "    'weight_decay': 5e-5,\n",
    "    'dropout_rate': 0.3,\n",
    "    'ensemble_size': 5\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded successfully\")\n",
    "print(f\"Input size: {CONFIG['input_size']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Learning rate: {CONFIG['learning_rate']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5733ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.augmentation import TMJAugmentations, MixUp3D, CutMix3D\n",
    "\n",
    "tmj_augment_train = TMJAugmentations(training=True)\n",
    "tmj_augment_val = TMJAugmentations(training=False)\n",
    "mixup = MixUp3D(alpha=0.2)\n",
    "cutmix = CutMix3D(alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1681ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating data structure at C:\\Users\\acer\\Desktop\\Project_TMJOA\\Data\\training_dataset_3D...\n",
      "‚úÖ train/0: 114 valid files\n",
      "‚úÖ train/1: 140 valid files\n",
      "‚úÖ val/0: 33 valid files\n",
      "‚úÖ val/1: 40 valid files\n",
      "‚úÖ test/0: 16 valid files\n",
      "‚úÖ test/1: 21 valid files\n",
      "‚úÖ Data structure validation passed!\n",
      "Loaded train split with 254 samples:\n",
      "  Class 0: 114 samples\n",
      "  Class 1: 140 samples\n",
      "Loaded val split with 73 samples:\n",
      "  Class 0: 33 samples\n",
      "  Class 1: 40 samples\n",
      "Loaded test split with 37 samples:\n",
      "  Class 0: 16 samples\n",
      "  Class 1: 21 samples\n",
      "Using balanced sampling for training data\n",
      "\n",
      "DataLoaders created:\n",
      "  Train: 254 samples, 63 batches\n",
      "  Val:   73 samples, 19 batches\n",
      "  Test:  37 samples, 10 batches\n",
      "\n",
      "Train sample shape: torch.Size([1, 254, 254, 254])\n",
      "Train sample label: 0\n",
      "Train sample patient ID: 48-26453 L\n",
      "‚úÖ Dataset loading successful!\n"
     ]
    }
   ],
   "source": [
    "from utils.unit_test import validate_data_structure\n",
    "from utils.dataloader import create_dataloaders\n",
    "\n",
    "# Validate data structure first\n",
    "if validate_data_structure(CONFIG['data_path']):\n",
    "    # Create all dataloaders\n",
    "    train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset = create_dataloaders(\n",
    "        CONFIG['data_path'], \n",
    "        CONFIG, \n",
    "        use_balanced_sampling=True\n",
    "    )\n",
    "    \n",
    "    # Test loading a sample from each split\n",
    "    if len(train_dataset) > 0:\n",
    "        sample_volume, sample_label, sample_patient = train_dataset[0]\n",
    "        print(f\"\\nTrain sample shape: {sample_volume.shape}\")\n",
    "        print(f\"Train sample label: {sample_label}\")\n",
    "        print(f\"Train sample patient ID: {sample_patient}\")\n",
    "    \n",
    "    print(\"‚úÖ Dataset loading successful!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Please fix data structure before proceeding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9372ff4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 3D ResNet model...\n",
      "Model created: ResNet3D\n",
      "Total parameters: 33,161,026\n",
      "Trainable parameters: 33,161,026\n",
      "Model test successful - Output shape: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "from utils.model import create_medical_resnet3d\n",
    "\n",
    "print(\"Creating 3D ResNet model...\")\n",
    "model = create_medical_resnet3d(\n",
    "    arch='resnet18',  # Start with ResNet-18 for smaller datasets\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    pretrained_path=None  # Add path to MedicalNet weights if available\n",
    ")\n",
    "\n",
    "print(f\"Model created: {model.__class__.__name__}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Test model with sample input\n",
    "try:\n",
    "    test_input = torch.randn(1, 1, *CONFIG['input_size'])\n",
    "    with torch.no_grad():\n",
    "        test_output = model(test_input)\n",
    "    print(f\"Model test successful - Output shape: {test_output.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Model test failed: {e}\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e67535c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced training functions with comprehensive logging:\n",
      "- üìä CSV logging for all metrics\n",
      "- üíæ Automatic best and last model saving\n",
      "- üìà Real-time progress bars for batches\n",
      "- üñ®Ô∏è  Detailed epoch results printing\n",
      "- üîß GPU memory monitoring\n",
      "- ‚è±Ô∏è  Timing information\n",
      "- üõë Enhanced early stopping\n",
      "- üìÅ Organized checkpoint management\n"
     ]
    }
   ],
   "source": [
    "# Block 6: Training and Validation Functions with Enhanced Logging\n",
    "\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "class CSVLogger:\n",
    "    \"\"\"CSV logger for training metrics\"\"\"\n",
    "    def __init__(self, log_path):\n",
    "        self.log_path = log_path\n",
    "        self.fieldnames = ['epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'val_auc', 'lr', 'best_val_acc']\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
    "        \n",
    "        # Initialize CSV file with headers\n",
    "        with open(self.log_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=self.fieldnames)\n",
    "            writer.writeheader()\n",
    "    \n",
    "    def log_epoch(self, epoch, train_loss, train_acc, val_loss, val_acc, val_auc, lr, best_val_acc):\n",
    "        \"\"\"Log metrics for one epoch\"\"\"\n",
    "        with open(self.log_path, 'a', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=self.fieldnames)\n",
    "            writer.writerow({\n",
    "                'epoch': epoch,\n",
    "                'train_loss': f'{train_loss:.6f}',\n",
    "                'train_acc': f'{train_acc:.6f}',\n",
    "                'val_loss': f'{val_loss:.6f}',\n",
    "                'val_acc': f'{val_acc:.6f}',\n",
    "                'val_auc': f'{val_auc:.6f}',\n",
    "                'lr': f'{lr:.8f}',\n",
    "                'best_val_acc': f'{best_val_acc:.6f}'\n",
    "            })\n",
    "\n",
    "class ModelCheckpoint:\n",
    "    \"\"\"Enhanced model checkpoint saving\"\"\"\n",
    "    def __init__(self, save_dir, model_name='model'):\n",
    "        self.save_dir = Path(save_dir)\n",
    "        self.save_dir.mkdir(exist_ok=True)\n",
    "        self.model_name = model_name\n",
    "        self.best_val_acc = -1.0\n",
    "        \n",
    "    def save_checkpoint(self, model, optimizer, scheduler, epoch, metrics, is_best=False, is_last=False):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "            'metrics': metrics,\n",
    "            'best_val_acc': self.best_val_acc\n",
    "        }\n",
    "        \n",
    "        if is_best:\n",
    "            best_path = self.save_dir / f'{self.model_name}_best.pt'\n",
    "            torch.save(checkpoint, best_path)\n",
    "            print(f\"üíæ Saved best model: {best_path}\")\n",
    "            \n",
    "        if is_last:\n",
    "            last_path = self.save_dir / f'{self.model_name}_last.pt'\n",
    "            torch.save(checkpoint, last_path)\n",
    "            print(f\"üíæ Saved last model: {last_path}\")\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
    "    def __init__(self, patience=20, min_delta=0.001, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            \n",
    "        if self.counter >= self.patience:\n",
    "            if self.restore_best_weights:\n",
    "                model.load_state_dict(self.best_weights)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        self.best_weights = model.state_dict().copy()\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Loss function for MixUp\"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device, epoch, use_mixup=True, use_cutmix=True):\n",
    "    \"\"\"Train for one epoch with progress bar and memory optimization\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Progress bar\n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch:3d} [Train]', \n",
    "                leave=False, ncols=100, ascii=True)\n",
    "    \n",
    "    for batch_idx, (inputs, targets, _) in enumerate(pbar):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Clear cache every few batches to prevent memory buildup\n",
    "        if batch_idx % 5 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Random choice between normal training, MixUp, and CutMix\n",
    "        r = np.random.rand(1)\n",
    "        if use_mixup and r < 0.3:\n",
    "            # MixUp augmentation\n",
    "            inputs, targets_a, targets_b, lam = mixup(inputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "            \n",
    "        elif use_cutmix and r < 0.6:\n",
    "            # CutMix augmentation\n",
    "            inputs, targets_a, targets_b, lam = cutmix(inputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "            \n",
    "        else:\n",
    "            # Normal training\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        if r >= 0.6:  # Only count predictions for normal training\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == targets.data)\n",
    "            total_samples += targets.size(0)\n",
    "        else:\n",
    "            total_samples += targets.size(0)\n",
    "        \n",
    "        # Update progress bar\n",
    "        current_loss = running_loss / ((batch_idx + 1) * dataloader.batch_size)\n",
    "        current_acc = (running_corrects.double() / total_samples).item() if total_samples > 0 else 0.0\n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{current_loss:.4f}',\n",
    "            'Acc': f'{current_acc:.4f}',\n",
    "            'GPU': f'{torch.cuda.memory_allocated()/1024**3:.1f}GB' if torch.cuda.is_available() else 'CPU'\n",
    "        })\n",
    "        \n",
    "        # Delete intermediate variables to free memory\n",
    "        del outputs, loss\n",
    "        if 'targets_a' in locals():\n",
    "            del targets_a, targets_b\n",
    "        \n",
    "        # Clear cache periodically\n",
    "        if batch_idx % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / total_samples if total_samples > 0 else 0.0\n",
    "    \n",
    "    # Final cache clear\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return epoch_loss, epoch_acc.item()\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device, epoch):\n",
    "    \"\"\"Validate for one epoch with progress bar\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Progress bar\n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch:3d} [Val]  ', \n",
    "                leave=False, ncols=100, ascii=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets, _) in enumerate(pbar):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == targets.data)\n",
    "            \n",
    "            # Store predictions for metrics\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            current_loss = running_loss / ((batch_idx + 1) * dataloader.batch_size)\n",
    "            current_acc = (running_corrects.double() / ((batch_idx + 1) * dataloader.batch_size)).item()\n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{current_loss:.4f}',\n",
    "                'Acc': f'{current_acc:.4f}'\n",
    "            })\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    \n",
    "    # Calculate AUC if binary classification\n",
    "    try:\n",
    "        if len(np.unique(all_labels)) == 2:\n",
    "            auc = roc_auc_score(all_labels, [p[1] for p in all_probs])\n",
    "        else:\n",
    "            auc = 0.0\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    \n",
    "    return epoch_loss, epoch_acc.item(), auc, all_preds, all_labels, all_probs\n",
    "\n",
    "def print_epoch_results(epoch, num_epochs, train_loss, train_acc, val_loss, val_acc, val_auc, \n",
    "                       lr, best_val_acc, time_elapsed):\n",
    "    \"\"\"Print detailed epoch results\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"EPOCH {epoch+1:3d}/{num_epochs} RESULTS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"‚è±Ô∏è  Time: {time_elapsed:.1f}s\")\n",
    "    print(f\"üìö Learning Rate: {lr:.8f}\")\n",
    "    print(f\"\")\n",
    "    print(f\"üèãÔ∏è  TRAINING   ‚Üí Loss: {train_loss:.6f} | Acc: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "    print(f\"‚úÖ VALIDATION ‚Üí Loss: {val_loss:.6f} | Acc: {val_acc:.4f} ({val_acc*100:.2f}%) | AUC: {val_auc:.4f}\")\n",
    "    print(f\"üèÜ BEST VAL   ‚Üí Acc: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üîß GPU Memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB / {torch.cuda.max_memory_allocated()/1024**3:.2f}GB peak\")\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "def train_model_with_validation(model, train_loader, val_loader, criterion, optimizer, \n",
    "                               scheduler, num_epochs, device, fold=None, save_dir=None):\n",
    "    \"\"\"Complete training loop with enhanced logging and checkpointing\"\"\"\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    # Setup logging and checkpointing\n",
    "    if save_dir is None:\n",
    "        save_dir = Path(\"tmj_results\") / \"checkpoints\"\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Model name for saving\n",
    "    model_name = f\"tmj_model_fold{fold}\" if fold else \"tmj_model\"\n",
    "    \n",
    "    # Initialize loggers\n",
    "    csv_logger = CSVLogger(save_dir / f\"{model_name}_training_log.csv\")\n",
    "    checkpoint_manager = ModelCheckpoint(save_dir, model_name)\n",
    "    early_stopping = EarlyStopping(patience=CONFIG['early_stopping_patience'])\n",
    "    \n",
    "    # Initialize tracking\n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs, val_aucs = [], [], []\n",
    "    \n",
    "    # Best model tracking\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    print(f\"\\nüöÄ Starting Training {'for ' + str(fold) if fold else ''}\")\n",
    "    print(f\"üìÅ Logs and models will be saved to: {save_dir}\")\n",
    "    print(f\"üìä CSV log: {model_name}_training_log.csv\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, epoch\n",
    "        )\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_acc, val_auc, val_preds, val_labels, val_probs = validate_epoch(\n",
    "            model, val_loader, criterion, device, epoch\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(val_loss)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Get current learning rate\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Update best accuracy\n",
    "        is_best = val_acc > best_val_acc\n",
    "        if is_best:\n",
    "            best_val_acc = val_acc\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        val_aucs.append(val_auc)\n",
    "        \n",
    "        # Calculate epoch time\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        # Print detailed results\n",
    "        print_epoch_results(epoch, num_epochs, train_loss, train_acc, val_loss, val_acc, \n",
    "                          val_auc, current_lr, best_val_acc, epoch_time)\n",
    "        \n",
    "        # Log to CSV\n",
    "        csv_logger.log_epoch(epoch, train_loss, train_acc, val_loss, val_acc, val_auc, \n",
    "                           current_lr, best_val_acc)\n",
    "        \n",
    "        # Save checkpoints\n",
    "        metrics = {\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_auc': val_auc\n",
    "        }\n",
    "        \n",
    "        checkpoint_manager.save_checkpoint(\n",
    "            model, optimizer, scheduler, epoch, metrics, \n",
    "            is_best=is_best, is_last=(epoch == num_epochs - 1)\n",
    "        )\n",
    "        \n",
    "        # Early stopping check\n",
    "        if early_stopping(val_loss, model):\n",
    "            print(f'\\nüõë Early stopping triggered at epoch {epoch+1}')\n",
    "            print(f\"   Best validation accuracy: {best_val_acc:.4f}\")\n",
    "            break\n",
    "    \n",
    "    # Final validation metrics\n",
    "    final_val_loss, final_val_acc, final_val_auc, final_preds, final_labels, final_probs = validate_epoch(\n",
    "        model, val_loader, criterion, device, num_epochs\n",
    "    )\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(final_labels, final_preds)\n",
    "    \n",
    "    print(f\"\\nüèÅ TRAINING COMPLETED!\")\n",
    "    print(f\"üìä Final Results:\")\n",
    "    print(f\"   Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "    print(f\"   Final Validation Accuracy: {final_val_acc:.4f}\")\n",
    "    print(f\"   Final Validation AUC: {final_val_auc:.4f}\")\n",
    "    print(f\"üìÅ All logs and models saved to: {save_dir}\")\n",
    "    \n",
    "    history = {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accs': val_accs,\n",
    "        'val_aucs': val_aucs,\n",
    "        'final_val_acc': final_val_acc,\n",
    "        'final_val_auc': final_val_auc,\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'confusion_matrix': cm,\n",
    "        'val_predictions': final_preds,\n",
    "        'val_labels': final_labels,\n",
    "        'val_probabilities': final_probs,\n",
    "        'save_dir': save_dir,\n",
    "        'model_name': model_name\n",
    "    }\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def create_optimizer_and_scheduler(model, train_loader):\n",
    "    \"\"\"Create optimizer and learning rate scheduler\"\"\"\n",
    "    \n",
    "    # AdamW optimizer with weight decay\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CONFIG['learning_rate'],\n",
    "        weight_decay=CONFIG['weight_decay'],\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    \n",
    "    # Cosine annealing with warm restarts\n",
    "    scheduler = CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=CONFIG['num_epochs'] // 4,  # Restart every 1/4 of total epochs\n",
    "        eta_min=CONFIG['learning_rate'] * 0.01\n",
    "    )\n",
    "    \n",
    "    return optimizer, scheduler\n",
    "\n",
    "print(\"Enhanced training functions with comprehensive logging:\")\n",
    "print(\"- üìä CSV logging for all metrics\")\n",
    "print(\"- üíæ Automatic best and last model saving\")\n",
    "print(\"- üìà Real-time progress bars for batches\")\n",
    "print(\"- üñ®Ô∏è  Detailed epoch results printing\")\n",
    "print(\"- üîß GPU memory monitoring\")\n",
    "print(\"- ‚è±Ô∏è  Timing information\")\n",
    "print(\"- üõë Enhanced early stopping\")\n",
    "print(\"- üìÅ Organized checkpoint management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdc2b36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluation functions updated for pre-split data:\n",
      "- train_single_model(): Train one model on pre-split data\n",
      "- train_ensemble_models(): Train multiple models with different seeds\n",
      "- evaluate_ensemble(): Comprehensive ensemble evaluation\n",
      "- evaluate_single_model(): Single model evaluation\n",
      "- comprehensive_model_evaluation(): Evaluation with visualizations\n",
      "- Enhanced plotting functions with save options\n"
     ]
    }
   ],
   "source": [
    "# Block 7: Training and Evaluation Functions for Pre-Split Data\n",
    "\n",
    "from utils.model import FocalLoss\n",
    "\n",
    "def train_single_model(train_loader, val_loader, config):\n",
    "    \"\"\"Train a single model using pre-split data\"\"\"\n",
    "    \n",
    "    print(\"Training single model on pre-split data...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Create model\n",
    "    model = create_medical_resnet3d(\n",
    "        arch='resnet18',\n",
    "        num_classes=config['num_classes']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create optimizer and scheduler\n",
    "    optimizer, scheduler = create_optimizer_and_scheduler(model, train_loader)\n",
    "    \n",
    "    # Create loss function (Focal Loss for imbalance)\n",
    "    criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "    \n",
    "    # Train the model\n",
    "    trained_model, history = train_model_with_validation(\n",
    "        model, train_loader, val_loader, criterion, optimizer,\n",
    "        scheduler, config['num_epochs'], device\n",
    "    )\n",
    "    \n",
    "    print(f\"Single model training completed!\")\n",
    "    print(f\"  Final Val Accuracy: {history['final_val_acc']:.4f}\")\n",
    "    print(f\"  Final Val AUC: {history['final_val_auc']:.4f}\")\n",
    "    \n",
    "    return trained_model, history\n",
    "\n",
    "def train_ensemble_models(train_loader, val_loader, config, num_models=5):\n",
    "    \"\"\"Train ensemble of models with different initializations using pre-split data\"\"\"\n",
    "    \n",
    "    print(f\"Training ensemble of {num_models} models on pre-split data...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    ensemble_models = []\n",
    "    ensemble_results = []\n",
    "    \n",
    "    for model_idx in range(num_models):\n",
    "        print(f\"\\nTraining Ensemble Model {model_idx + 1}/{num_models}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Set different random seed for each model\n",
    "        set_seed(42 + model_idx * 10)\n",
    "        \n",
    "        # Create model with different initialization\n",
    "        model = create_medical_resnet3d(\n",
    "            arch='resnet18',\n",
    "            num_classes=config['num_classes']\n",
    "        ).to(device)\n",
    "        \n",
    "        # Create optimizer and scheduler\n",
    "        optimizer, scheduler = create_optimizer_and_scheduler(model, train_loader)\n",
    "        \n",
    "        # Create loss function\n",
    "        criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "        \n",
    "        # Train the model\n",
    "        trained_model, history = train_model_with_validation(\n",
    "            model, train_loader, val_loader, criterion, optimizer,\n",
    "            scheduler, config['num_epochs'], device, fold=f\"Model_{model_idx+1}\"\n",
    "        )\n",
    "        \n",
    "        # Store model and results\n",
    "        ensemble_models.append(trained_model.state_dict().copy())\n",
    "        ensemble_results.append(history)\n",
    "        \n",
    "        print(f\"Model {model_idx + 1} - Val Accuracy: {history['final_val_acc']:.4f}\")\n",
    "    \n",
    "    # Calculate ensemble statistics\n",
    "    val_accs = [result['final_val_acc'] for result in ensemble_results]\n",
    "    val_aucs = [result['final_val_auc'] for result in ensemble_results]\n",
    "    \n",
    "    print(f\"\\nEnsemble Training Results:\")\n",
    "    print(f\"Individual accuracies: {[f'{acc:.4f}' for acc in val_accs]}\")\n",
    "    print(f\"Individual AUCs: {[f'{auc:.4f}' for auc in val_aucs]}\")\n",
    "    print(f\"Mean accuracy: {np.mean(val_accs):.4f} ¬± {np.std(val_accs):.4f}\")\n",
    "    print(f\"Mean AUC: {np.mean(val_aucs):.4f} ¬± {np.std(val_aucs):.4f}\")\n",
    "    \n",
    "    return ensemble_models, ensemble_results\n",
    "\n",
    "def evaluate_ensemble(ensemble_models, test_loader, device):\n",
    "    \"\"\"Evaluate ensemble of models on test set\"\"\"\n",
    "    \n",
    "    print(\"Evaluating ensemble on test set...\")\n",
    "    \n",
    "    # Create a model architecture for loading weights\n",
    "    base_model = create_medical_resnet3d(\n",
    "        arch='resnet18',\n",
    "        num_classes=CONFIG['num_classes']\n",
    "    ).to(device)\n",
    "    \n",
    "    all_ensemble_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    for model_idx, model_weights in enumerate(ensemble_models):\n",
    "        print(f\"Getting predictions from model {model_idx + 1}/{len(ensemble_models)}...\")\n",
    "        \n",
    "        base_model.load_state_dict(model_weights)\n",
    "        base_model.eval()\n",
    "        \n",
    "        model_probs = []\n",
    "        labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets, _ in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                outputs = base_model(inputs)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                \n",
    "                model_probs.extend(probs.cpu().numpy())\n",
    "                if model_idx == 0:  # Only store labels once\n",
    "                    labels.extend(targets.cpu().numpy())\n",
    "        \n",
    "        all_ensemble_probs.append(model_probs)\n",
    "        if model_idx == 0:\n",
    "            all_labels = labels\n",
    "    \n",
    "    # Average ensemble predictions\n",
    "    ensemble_probs = np.mean(all_ensemble_probs, axis=0)\n",
    "    ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    ensemble_acc = accuracy_score(all_labels, ensemble_preds)\n",
    "    try:\n",
    "        ensemble_auc = roc_auc_score(all_labels, ensemble_probs[:, 1]) if ensemble_probs.shape[1] > 1 else 0.0\n",
    "    except:\n",
    "        ensemble_auc = 0.0\n",
    "    \n",
    "    # Individual model accuracies\n",
    "    individual_accs = []\n",
    "    individual_aucs = []\n",
    "    for model_probs in all_ensemble_probs:\n",
    "        model_preds = np.argmax(model_probs, axis=1)\n",
    "        model_acc = accuracy_score(all_labels, model_preds)\n",
    "        individual_accs.append(model_acc)\n",
    "        \n",
    "        try:\n",
    "            model_auc = roc_auc_score(all_labels, np.array(model_probs)[:, 1]) if len(model_probs[0]) > 1 else 0.0\n",
    "            individual_aucs.append(model_auc)\n",
    "        except:\n",
    "            individual_aucs.append(0.0)\n",
    "    \n",
    "    print(f\"\\nüéØ ENSEMBLE EVALUATION RESULTS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Individual model accuracies: {[f'{acc:.4f}' for acc in individual_accs]}\")\n",
    "    print(f\"Individual model AUCs: {[f'{auc:.4f}' for auc in individual_aucs]}\")\n",
    "    print(f\"Ensemble accuracy: {ensemble_acc:.4f}\")\n",
    "    print(f\"Ensemble AUC: {ensemble_auc:.4f}\")\n",
    "    print(f\"Best individual accuracy: {max(individual_accs):.4f}\")\n",
    "    print(f\"Improvement over best individual: {ensemble_acc - max(individual_accs):+.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, ensemble_preds)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return {\n",
    "        'ensemble_accuracy': ensemble_acc,\n",
    "        'ensemble_auc': ensemble_auc,\n",
    "        'individual_accuracies': individual_accs,\n",
    "        'individual_aucs': individual_aucs,\n",
    "        'ensemble_predictions': ensemble_preds,\n",
    "        'ensemble_probabilities': ensemble_probs,\n",
    "        'labels': all_labels,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "def evaluate_single_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate a single model on test set\"\"\"\n",
    "    \n",
    "    print(\"Evaluating single model on test set...\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, _ in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, [p[1] for p in all_probs]) if len(all_probs[0]) > 1 else 0.0\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"\\nüéØ SINGLE MODEL TEST RESULTS:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test AUC: {auc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc,\n",
    "        'predictions': all_preds,\n",
    "        'probabilities': all_probs,\n",
    "        'labels': all_labels,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "def plot_training_history(histories, title_prefix=\"\", save_path=None):\n",
    "    \"\"\"Plot training curves from training history\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    for i, history in enumerate(histories):\n",
    "        # Training and validation loss\n",
    "        axes[0, 0].plot(history['train_losses'], label=f'Model {i+1} Train', alpha=0.7)\n",
    "        axes[0, 1].plot(history['val_losses'], label=f'Model {i+1} Val', alpha=0.7)\n",
    "        \n",
    "        # Training and validation accuracy\n",
    "        axes[1, 0].plot(history['train_accs'], label=f'Model {i+1} Train', alpha=0.7)\n",
    "        axes[1, 1].plot(history['val_accs'], label=f'Model {i+1} Val', alpha=0.7)\n",
    "    \n",
    "    axes[0, 0].set_title(f'{title_prefix}Training Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].set_title(f'{title_prefix}Validation Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 0].set_title(f'{title_prefix}Training Accuracy')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Accuracy')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 1].set_title(f'{title_prefix}Validation Accuracy')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Training curves saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names=['Healthy', 'Osteoarthritis'], title='Confusion Matrix', save_path=None):\n",
    "    \"\"\"Plot confusion matrix with proper formatting\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Confusion matrix saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def comprehensive_model_evaluation(model_or_models, test_loader, device, is_ensemble=False):\n",
    "    \"\"\"Comprehensive evaluation with visualizations\"\"\"\n",
    "    \n",
    "    if is_ensemble:\n",
    "        results = evaluate_ensemble(model_or_models, test_loader, device)\n",
    "        \n",
    "        # Plot confusion matrix for ensemble\n",
    "        plot_confusion_matrix(\n",
    "            results['confusion_matrix'], \n",
    "            title='Ensemble Model - Test Set Confusion Matrix'\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        results = evaluate_single_model(model_or_models, test_loader, device)\n",
    "        \n",
    "        # Plot confusion matrix for single model\n",
    "        plot_confusion_matrix(\n",
    "            results['confusion_matrix'], \n",
    "            title='Single Model - Test Set Confusion Matrix'\n",
    "        )\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Training and evaluation functions updated for pre-split data:\")\n",
    "print(\"- train_single_model(): Train one model on pre-split data\")\n",
    "print(\"- train_ensemble_models(): Train multiple models with different seeds\")\n",
    "print(\"- evaluate_ensemble(): Comprehensive ensemble evaluation\")\n",
    "print(\"- evaluate_single_model(): Single model evaluation\") \n",
    "print(\"- comprehensive_model_evaluation(): Evaluation with visualizations\")\n",
    "print(\"- Enhanced plotting functions with save options\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba7acd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Validating Training Setup...\n",
      "----------------------------------------\n",
      "Validating data structure at C:\\Users\\acer\\Desktop\\Project_TMJOA\\Data\\training_dataset_3D...\n",
      "‚úÖ train/0: 114 valid files\n",
      "‚úÖ train/1: 140 valid files\n",
      "‚úÖ val/0: 33 valid files\n",
      "‚úÖ val/1: 40 valid files\n",
      "‚úÖ test/0: 16 valid files\n",
      "‚úÖ test/1: 21 valid files\n",
      "‚úÖ Data structure validation passed!\n",
      "‚úÖ Data structure validation passed\n",
      "‚ö†Ô∏è  GPU not available, will use CPU (slower)\n",
      "Loaded train split with 254 samples:\n",
      "  Class 0: 114 samples\n",
      "  Class 1: 140 samples\n",
      "Loaded val split with 73 samples:\n",
      "  Class 0: 33 samples\n",
      "  Class 1: 40 samples\n",
      "Loaded test split with 37 samples:\n",
      "  Class 0: 16 samples\n",
      "  Class 1: 21 samples\n",
      "Using balanced sampling for training data\n",
      "\n",
      "DataLoaders created:\n",
      "  Train: 254 samples, 63 batches\n",
      "  Val:   73 samples, 19 batches\n",
      "  Test:  37 samples, 10 batches\n",
      "‚úÖ Data loading works, batch shape: torch.Size([4, 1, 254, 254, 254])\n",
      "‚úÖ Model creation successful\n",
      "‚úÖ Model forward pass successful, output shape: torch.Size([1, 2])\n",
      "‚úÖ Results directory writable\n",
      "\n",
      "üìä Setup Validation: 6/6 checks passed\n",
      "üéâ All checks passed! Ready to train.\n",
      "\n",
      "==================================================\n",
      "üöÄ READY TO START TRAINING!\n",
      "==================================================\n",
      "Run: main_training_pipeline()\n",
      "Or for quick test: quick_train()\n",
      "==================================================\n",
      "\n",
      "======================================================================\n",
      "TMJ 3D CNN TRAINING SCRIPT - PRE-SPLIT DATA VERSION\n",
      "======================================================================\n",
      "\n",
      "Available functions:\n",
      "‚Ä¢ main_training_pipeline() - Complete training pipeline\n",
      "‚Ä¢ quick_train() - Fast training for testing (5 epochs)\n",
      "‚Ä¢ validate_training_setup() - Check if everything is ready\n",
      "‚Ä¢ load_and_inference(model_path, test_loader) - Load and test models\n",
      "\n",
      "Update CONFIG['data_path'] then run main_training_pipeline()!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Block 8: Main Training Execution for Pre-Split Data\n",
    "\n",
    "def main_training_pipeline():\n",
    "    \"\"\"Main pipeline for TMJ classification model training with pre-split data\"\"\"\n",
    "    \n",
    "    print(\"Starting TMJ 3D CNN Training Pipeline with Pre-Split Data\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Step 1: Validate data structure and load datasets\n",
    "    print(\"\\n1. Validating data structure and loading datasets...\")\n",
    "    try:\n",
    "        if not validate_data_structure(CONFIG['data_path']):\n",
    "            print(\"‚ùå Data structure validation failed. Please fix and try again.\")\n",
    "            return None\n",
    "        \n",
    "        # Create all dataloaders\n",
    "        train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset = create_dataloaders(\n",
    "            CONFIG['data_path'], \n",
    "            CONFIG, \n",
    "            use_balanced_sampling=True\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ All datasets loaded successfully!\")\n",
    "        \n",
    "        # Display dataset statistics\n",
    "        print(f\"\\nDataset Statistics:\")\n",
    "        print(f\"  Training:   {len(train_dataset)} samples\")\n",
    "        print(f\"  Validation: {len(val_dataset)} samples\") \n",
    "        print(f\"  Test:       {len(test_dataset)} samples\")\n",
    "        print(f\"  Total:      {len(train_dataset) + len(val_dataset) + len(test_dataset)} samples\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading datasets: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Choose training strategy\n",
    "    print(\"\\n2. Training Strategy Selection:\")\n",
    "    print(\"   a) Single model training (fastest, good for initial experiments)\")\n",
    "    print(\"   b) Ensemble training (best performance, multiple models)\")\n",
    "    print(\"   c) Both single and ensemble (comprehensive comparison)\")\n",
    "    \n",
    "    strategy = input(\"Choose strategy (a/b/c) [default: a]: \").lower().strip()\n",
    "    if strategy == '':\n",
    "        strategy = 'a'\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    if strategy == 'a':\n",
    "        # Single model training\n",
    "        print(\"\\n3. Training Single Model...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        model, history = train_single_model(train_loader, val_loader, CONFIG)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        print(\"\\n4. Evaluating on Test Set...\")\n",
    "        test_results = comprehensive_model_evaluation(\n",
    "            model, test_loader, device, is_ensemble=False\n",
    "        )\n",
    "        \n",
    "        # Plot training curves\n",
    "        plot_training_history([history], \"Single Model \")\n",
    "        \n",
    "        # Store results\n",
    "        results = {\n",
    "            'strategy': 'single_model',\n",
    "            'model': model.state_dict(),\n",
    "            'history': history,\n",
    "            'test_results': test_results\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nüéØ FINAL RESULTS - Single Model:\")\n",
    "        print(f\"  Validation Accuracy: {history['final_val_acc']:.4f}\")\n",
    "        print(f\"  Test Accuracy: {test_results['accuracy']:.4f}\")\n",
    "        print(f\"  Test AUC: {test_results['auc']:.4f}\")\n",
    "        \n",
    "    elif strategy == 'b':\n",
    "        # Ensemble training\n",
    "        print(\"\\n3. Training Ensemble Models...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        ensemble_models, ensemble_histories = train_ensemble_models(\n",
    "            train_loader, val_loader, CONFIG, num_models=CONFIG['ensemble_size']\n",
    "        )\n",
    "        \n",
    "        # Evaluate ensemble on test set\n",
    "        print(\"\\n4. Evaluating Ensemble on Test Set...\")\n",
    "        test_results = comprehensive_model_evaluation(\n",
    "            ensemble_models, test_loader, device, is_ensemble=True\n",
    "        )\n",
    "        \n",
    "        # Plot training curves\n",
    "        plot_training_history(ensemble_histories, \"Ensemble \")\n",
    "        \n",
    "        # Store results\n",
    "        results = {\n",
    "            'strategy': 'ensemble',\n",
    "            'models': ensemble_models,\n",
    "            'histories': ensemble_histories,\n",
    "            'test_results': test_results\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nüéØ FINAL RESULTS - Ensemble:\")\n",
    "        val_accs = [h['final_val_acc'] for h in ensemble_histories]\n",
    "        print(f\"  Validation Accuracy: {np.mean(val_accs):.4f} ¬± {np.std(val_accs):.4f}\")\n",
    "        print(f\"  Test Accuracy: {test_results['ensemble_accuracy']:.4f}\")\n",
    "        print(f\"  Test AUC: {test_results['ensemble_auc']:.4f}\")\n",
    "        \n",
    "    else:\n",
    "        # Both single and ensemble\n",
    "        print(\"\\n3. Training Both Single Model and Ensemble...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Train single model\n",
    "        print(\"\\n3a. Training Single Model...\")\n",
    "        single_model, single_history = train_single_model(train_loader, val_loader, CONFIG)\n",
    "        \n",
    "        # Train ensemble\n",
    "        print(\"\\n3b. Training Ensemble Models...\")\n",
    "        ensemble_models, ensemble_histories = train_ensemble_models(\n",
    "            train_loader, val_loader, CONFIG, num_models=CONFIG['ensemble_size']\n",
    "        )\n",
    "        \n",
    "        # Evaluate both on test set\n",
    "        print(\"\\n4. Evaluating Both Approaches on Test Set...\")\n",
    "        \n",
    "        print(\"\\n4a. Single Model Test Results:\")\n",
    "        single_test_results = comprehensive_model_evaluation(\n",
    "            single_model, test_loader, device, is_ensemble=False\n",
    "        )\n",
    "        \n",
    "        print(\"\\n4b. Ensemble Test Results:\")\n",
    "        ensemble_test_results = comprehensive_model_evaluation(\n",
    "            ensemble_models, test_loader, device, is_ensemble=True\n",
    "        )\n",
    "        \n",
    "        # Plot training curves\n",
    "        plot_training_history([single_history], \"Single Model \")\n",
    "        plot_training_history(ensemble_histories, \"Ensemble \")\n",
    "        \n",
    "        # Store results\n",
    "        results = {\n",
    "            'strategy': 'both',\n",
    "            'single_model': single_model.state_dict(),\n",
    "            'single_history': single_history,\n",
    "            'single_test_results': single_test_results,\n",
    "            'ensemble_models': ensemble_models,\n",
    "            'ensemble_histories': ensemble_histories,\n",
    "            'ensemble_test_results': ensemble_test_results\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nüéØ FINAL COMPARISON:\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"Single Model:\")\n",
    "        print(f\"  Test Accuracy: {single_test_results['accuracy']:.4f}\")\n",
    "        print(f\"  Test AUC: {single_test_results['auc']:.4f}\")\n",
    "        print(f\"Ensemble Model:\")\n",
    "        print(f\"  Test Accuracy: {ensemble_test_results['ensemble_accuracy']:.4f}\")\n",
    "        print(f\"  Test AUC: {ensemble_test_results['ensemble_auc']:.4f}\")\n",
    "        print(f\"Ensemble Improvement: {ensemble_test_results['ensemble_accuracy'] - single_test_results['accuracy']:+.4f}\")\n",
    "    \n",
    "    # Step 5: Save results\n",
    "    print(f\"\\n5. Saving Results...\")\n",
    "    save_results(results, strategy)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_results(results, strategy_name):\n",
    "    \"\"\"Save training results and models for pre-split data\"\"\"\n",
    "    \n",
    "    import pickle\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Create results directory\n",
    "    results_dir = Path(\"tmj_results\")\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save training results\n",
    "    results_file = results_dir / f\"{strategy_name}_results_{timestamp}.pkl\"\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'results': results,\n",
    "            'config': CONFIG,\n",
    "            'strategy': strategy_name,\n",
    "            'timestamp': timestamp\n",
    "        }, f)\n",
    "    \n",
    "    # Save model weights\n",
    "    if strategy_name == 'single_model':\n",
    "        models_file = results_dir / f\"single_model_{timestamp}.pt\"\n",
    "        torch.save(results['model'], models_file)\n",
    "    elif strategy_name == 'ensemble':\n",
    "        models_file = results_dir / f\"ensemble_models_{timestamp}.pt\"\n",
    "        torch.save(results['models'], models_file)\n",
    "    else:  # both\n",
    "        single_file = results_dir / f\"single_model_{timestamp}.pt\"\n",
    "        ensemble_file = results_dir / f\"ensemble_models_{timestamp}.pt\"\n",
    "        torch.save(results['single_model'], single_file)\n",
    "        torch.save(results['ensemble_models'], ensemble_file)\n",
    "        models_file = f\"{single_file.name} & {ensemble_file.name}\"\n",
    "    \n",
    "    # Save detailed report\n",
    "    report_file = results_dir / f\"{strategy_name}_report_{timestamp}.txt\"\n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(f\"TMJ 3D CNN Training Report - {strategy_name.upper()}\\n\")\n",
    "        f.write(\"=\" * 70 + \"\\n\")\n",
    "        f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "        f.write(f\"Strategy: {strategy_name}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Configuration:\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        for key, value in CONFIG.items():\n",
    "            f.write(f\"  {key}: {value}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        if strategy_name == \"single_model\":\n",
    "            f.write(\"Single Model Results:\\n\")\n",
    "            f.write(\"-\" * 25 + \"\\n\")\n",
    "            f.write(f\"  Validation Accuracy: {results['history']['final_val_acc']:.4f}\\n\")\n",
    "            f.write(f\"  Validation AUC: {results['history']['final_val_auc']:.4f}\\n\")\n",
    "            f.write(f\"  Test Accuracy: {results['test_results']['accuracy']:.4f}\\n\")\n",
    "            f.write(f\"  Test AUC: {results['test_results']['auc']:.4f}\\n\")\n",
    "            \n",
    "        elif strategy_name == \"ensemble\":\n",
    "            val_accs = [h['final_val_acc'] for h in results['histories']]\n",
    "            val_aucs = [h['final_val_auc'] for h in results['histories']]\n",
    "            f.write(\"Ensemble Results:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(f\"  Validation Accuracy: {np.mean(val_accs):.4f} ¬± {np.std(val_accs):.4f}\\n\")\n",
    "            f.write(f\"  Validation AUC: {np.mean(val_aucs):.4f} ¬± {np.std(val_aucs):.4f}\\n\")\n",
    "            f.write(f\"  Test Accuracy: {results['test_results']['ensemble_accuracy']:.4f}\\n\")\n",
    "            f.write(f\"  Test AUC: {results['test_results']['ensemble_auc']:.4f}\\n\")\n",
    "            f.write(f\"  Individual Test Accuracies: {[f'{acc:.4f}' for acc in results['test_results']['individual_accuracies']]}\\n\")\n",
    "            \n",
    "        else:  # both\n",
    "            f.write(\"Comparison Results:\\n\")\n",
    "            f.write(\"-\" * 22 + \"\\n\")\n",
    "            f.write(\"Single Model:\\n\")\n",
    "            f.write(f\"  Test Accuracy: {results['single_test_results']['accuracy']:.4f}\\n\")\n",
    "            f.write(f\"  Test AUC: {results['single_test_results']['auc']:.4f}\\n\")\n",
    "            f.write(\"Ensemble Model:\\n\")\n",
    "            f.write(f\"  Test Accuracy: {results['ensemble_test_results']['ensemble_accuracy']:.4f}\\n\")\n",
    "            f.write(f\"  Test AUC: {results['ensemble_test_results']['ensemble_auc']:.4f}\\n\")\n",
    "            improvement = results['ensemble_test_results']['ensemble_accuracy'] - results['single_test_results']['accuracy']\n",
    "            f.write(f\"  Ensemble Improvement: {improvement:+.4f}\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ Results saved to: {results_dir}\")\n",
    "    print(f\"  - Training results: {results_file.name}\")\n",
    "    print(f\"  - Model weights: {models_file}\")\n",
    "    print(f\"  - Summary report: {report_file.name}\")\n",
    "\n",
    "def load_and_inference(model_path, test_loader, model_type='single'):\n",
    "    \"\"\"Load trained model and run inference on test data\"\"\"\n",
    "    \n",
    "    print(f\"Loading {model_type} model for inference...\")\n",
    "    \n",
    "    if model_type == 'ensemble':\n",
    "        # Load ensemble models\n",
    "        ensemble_models = torch.load(model_path, map_location=device)\n",
    "        print(f\"Loaded ensemble of {len(ensemble_models)} models\")\n",
    "        \n",
    "        # Evaluate ensemble\n",
    "        results = evaluate_ensemble(ensemble_models, test_loader, device)\n",
    "        return results\n",
    "        \n",
    "    else:\n",
    "        # Load single model\n",
    "        model_weights = torch.load(model_path, map_location=device)\n",
    "        print(\"Loaded single model\")\n",
    "        \n",
    "        # Create model architecture and load weights\n",
    "        model = create_medical_resnet3d(\n",
    "            arch='resnet18',\n",
    "            num_classes=CONFIG['num_classes']\n",
    "        ).to(device)\n",
    "        model.load_state_dict(model_weights)\n",
    "        \n",
    "        # Evaluate model\n",
    "        results = evaluate_single_model(model, test_loader, device)\n",
    "        return results\n",
    "\n",
    "def quick_train():\n",
    "    \"\"\"Quick training function for testing/debugging\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Quick Training Mode (reduced epochs for testing)\")\n",
    "    \n",
    "    # Temporarily reduce epochs for quick testing\n",
    "    original_epochs = CONFIG['num_epochs']\n",
    "    CONFIG['num_epochs'] = 5\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        train_loader, val_loader, test_loader, _, _, _ = create_dataloaders(\n",
    "            CONFIG['data_path'], CONFIG, use_balanced_sampling=True\n",
    "        )\n",
    "        \n",
    "        # Train single model quickly\n",
    "        model, history = train_single_model(train_loader, val_loader, CONFIG)\n",
    "        \n",
    "        # Quick evaluation\n",
    "        test_results = evaluate_single_model(model, test_loader, device)\n",
    "        \n",
    "        print(f\"‚úÖ Quick training completed!\")\n",
    "        print(f\"  Test Accuracy: {test_results['accuracy']:.4f}\")\n",
    "        \n",
    "        return model, history, test_results\n",
    "        \n",
    "    finally:\n",
    "        # Restore original epochs\n",
    "        CONFIG['num_epochs'] = original_epochs\n",
    "\n",
    "def validate_training_setup():\n",
    "    \"\"\"Validate that everything is set up correctly for training\"\"\"\n",
    "    \n",
    "    print(\"üîç Validating Training Setup...\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    checks_passed = 0\n",
    "    total_checks = 6\n",
    "    \n",
    "    # Check 1: Data structure\n",
    "    if validate_data_structure(CONFIG['data_path']):\n",
    "        print(\"‚úÖ Data structure validation passed\")\n",
    "        checks_passed += 1\n",
    "    else:\n",
    "        print(\"‚ùå Data structure validation failed\")\n",
    "    \n",
    "    # Check 2: GPU availability\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úÖ GPU available: {torch.cuda.get_device_name()}\")\n",
    "        checks_passed += 1\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  GPU not available, will use CPU (slower)\")\n",
    "        checks_passed += 1\n",
    "    \n",
    "    # Check 3: Try loading a small batch\n",
    "    try:\n",
    "        train_loader, _, _, _, _, _ = create_dataloaders(CONFIG['data_path'], CONFIG)\n",
    "        sample_batch = next(iter(train_loader))\n",
    "        print(f\"‚úÖ Data loading works, batch shape: {sample_batch[0].shape}\")\n",
    "        checks_passed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Data loading failed: {e}\")\n",
    "    \n",
    "    # Check 4: Model creation\n",
    "    try:\n",
    "        test_model = create_medical_resnet3d(arch='resnet18', num_classes=CONFIG['num_classes'])\n",
    "        print(f\"‚úÖ Model creation successful\")\n",
    "        checks_passed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model creation failed: {e}\")\n",
    "    \n",
    "    # Check 5: Forward pass test\n",
    "    try:\n",
    "        test_input = torch.randn(1, 1, *CONFIG['input_size'])\n",
    "        with torch.no_grad():\n",
    "            test_output = test_model(test_input)\n",
    "        print(f\"‚úÖ Model forward pass successful, output shape: {test_output.shape}\")\n",
    "        checks_passed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model forward pass failed: {e}\")\n",
    "    \n",
    "    # Check 6: Directory permissions\n",
    "    try:\n",
    "        results_dir = Path(\"tmj_results\")\n",
    "        results_dir.mkdir(exist_ok=True)\n",
    "        test_file = results_dir / \"test.txt\"\n",
    "        test_file.write_text(\"test\")\n",
    "        test_file.unlink()\n",
    "        print(\"‚úÖ Results directory writable\")\n",
    "        checks_passed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Cannot write to results directory: {e}\")\n",
    "    \n",
    "    print(f\"\\nüìä Setup Validation: {checks_passed}/{total_checks} checks passed\")\n",
    "    \n",
    "    if checks_passed == total_checks:\n",
    "        print(\"üéâ All checks passed! Ready to train.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Some checks failed. Please fix issues before training.\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if data path exists\n",
    "    if not os.path.exists(CONFIG['data_path']):\n",
    "        print(f\"‚ùå Error: Data path {CONFIG['data_path']} does not exist!\")\n",
    "        print(\"Please update CONFIG['data_path'] to point to your TMJ dataset\")\n",
    "        print(\"Expected structure:\")\n",
    "        print(\"  tmj_data/\")\n",
    "        print(\"    ‚îú‚îÄ‚îÄ train/\")\n",
    "        print(\"    ‚îÇ   ‚îú‚îÄ‚îÄ 0/  (class 0 files)\")\n",
    "        print(\"    ‚îÇ   ‚îî‚îÄ‚îÄ 1/  (class 1 files)\")\n",
    "        print(\"    ‚îú‚îÄ‚îÄ val/\")\n",
    "        print(\"    ‚îÇ   ‚îú‚îÄ‚îÄ 0/  (class 0 files)\")\n",
    "        print(\"    ‚îÇ   ‚îî‚îÄ‚îÄ 1/  (class 1 files)\")\n",
    "        print(\"    ‚îî‚îÄ‚îÄ test/\")\n",
    "        print(\"        ‚îú‚îÄ‚îÄ 0/  (class 0 files)\")\n",
    "        print(\"        ‚îî‚îÄ‚îÄ 1/  (class 1 files)\")\n",
    "    else:\n",
    "        # Validate setup\n",
    "        if validate_training_setup():\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"üöÄ READY TO START TRAINING!\")\n",
    "            print(\"=\"*50)\n",
    "            print(\"Run: main_training_pipeline()\")\n",
    "            print(\"Or for quick test: quick_train()\")\n",
    "            print(\"=\"*50)\n",
    "        else:\n",
    "            print(\"\\n‚ùå Please fix the issues above before proceeding.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TMJ 3D CNN TRAINING SCRIPT - PRE-SPLIT DATA VERSION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nAvailable functions:\")\n",
    "print(\"‚Ä¢ main_training_pipeline() - Complete training pipeline\")\n",
    "print(\"‚Ä¢ quick_train() - Fast training for testing (5 epochs)\")\n",
    "print(\"‚Ä¢ validate_training_setup() - Check if everything is ready\")\n",
    "print(\"‚Ä¢ load_and_inference(model_path, test_loader) - Load and test models\")\n",
    "print(\"\\nUpdate CONFIG['data_path'] then run main_training_pipeline()!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44086f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TMJ 3D CNN Training Pipeline with Pre-Split Data\n",
      "======================================================================\n",
      "\n",
      "1. Validating data structure and loading datasets...\n",
      "Validating data structure at C:\\Users\\acer\\Desktop\\Project_TMJOA\\Data\\training_dataset_3D...\n",
      "‚úÖ train/0: 114 valid files\n",
      "‚úÖ train/1: 140 valid files\n",
      "‚úÖ val/0: 33 valid files\n",
      "‚úÖ val/1: 40 valid files\n",
      "‚úÖ test/0: 16 valid files\n",
      "‚úÖ test/1: 21 valid files\n",
      "‚úÖ Data structure validation passed!\n",
      "Loaded train split with 254 samples:\n",
      "  Class 0: 114 samples\n",
      "  Class 1: 140 samples\n",
      "Loaded val split with 73 samples:\n",
      "  Class 0: 33 samples\n",
      "  Class 1: 40 samples\n",
      "Loaded test split with 37 samples:\n",
      "  Class 0: 16 samples\n",
      "  Class 1: 21 samples\n",
      "Using balanced sampling for training data\n",
      "\n",
      "DataLoaders created:\n",
      "  Train: 254 samples, 63 batches\n",
      "  Val:   73 samples, 19 batches\n",
      "  Test:  37 samples, 10 batches\n",
      "‚úÖ All datasets loaded successfully!\n",
      "\n",
      "Dataset Statistics:\n",
      "  Training:   254 samples\n",
      "  Validation: 73 samples\n",
      "  Test:       37 samples\n",
      "  Total:      364 samples\n",
      "\n",
      "2. Training Strategy Selection:\n",
      "   a) Single model training (fastest, good for initial experiments)\n",
      "   b) Ensemble training (best performance, multiple models)\n",
      "   c) Both single and ensemble (comprehensive comparison)\n",
      "\n",
      "3. Training Single Model...\n",
      "==================================================\n",
      "Training single model on pre-split data...\n",
      "--------------------------------------------------\n",
      "\n",
      "üöÄ Starting Training \n",
      "üìÅ Logs and models will be saved to: tmj_results\\checkpoints\n",
      "üìä CSV log: tmj_model_training_log.csv\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mmain_training_pipeline\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m3. Training Single Model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m model, history = \u001b[43mtrain_single_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Evaluate on test set\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m4. Evaluating on Test Set...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtrain_single_model\u001b[39m\u001b[34m(train_loader, val_loader, config)\u001b[39m\n\u001b[32m     21\u001b[39m criterion = FocalLoss(alpha=\u001b[32m0.25\u001b[39m, gamma=\u001b[32m2.0\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m trained_model, history = \u001b[43mtrain_model_with_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnum_epochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSingle model training completed!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Final Val Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory[\u001b[33m'\u001b[39m\u001b[33mfinal_val_acc\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 292\u001b[39m, in \u001b[36mtrain_model_with_validation\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, fold, save_dir)\u001b[39m\n\u001b[32m    289\u001b[39m epoch_start_time = time.time()\n\u001b[32m    291\u001b[39m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n\u001b[32m    297\u001b[39m val_loss, val_acc, val_auc, val_preds, val_labels, val_probs = validate_epoch(\n\u001b[32m    298\u001b[39m     model, val_loader, criterion, device, epoch\n\u001b[32m    299\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 130\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, dataloader, criterion, optimizer, device, epoch, use_mixup, use_cutmix)\u001b[39m\n\u001b[32m    128\u001b[39m     inputs, targets_a, targets_b, lam = cutmix(inputs, targets)\n\u001b[32m    129\u001b[39m     optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m     loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    134\u001b[39m     \u001b[38;5;66;03m# Normal training\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\Desktop\\Project_TMJOA\\3D_Pipeline\\project\\utils\\model.py:288\u001b[39m, in \u001b[36mResNet3D.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# Initial layers\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.bn1(x)\n\u001b[32m    290\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.relu(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:725\u001b[39m, in \u001b[36mConv3d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acer\\anaconda3\\envs\\3dmodel\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:720\u001b[39m, in \u001b[36mConv3d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    709\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv3d(\n\u001b[32m    710\u001b[39m         F.pad(\n\u001b[32m    711\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    718\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    719\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "main_training_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
